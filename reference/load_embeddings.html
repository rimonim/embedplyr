<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Load Pretrained GloVe, word2vec, and fastText Embeddings — load_embeddings • embedplyr</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png"><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Load Pretrained GloVe, word2vec, and fastText Embeddings — load_embeddings"><meta name="description" content="Loads pretrained word embeddings. If the specified model has already been
downloaded, it is read from file with read_embeddings(). If not, the model
is retrieved from online sources and, by default, saved."><meta property="og:description" content="Loads pretrained word embeddings. If the specified model has already been
downloaded, it is read from file with read_embeddings(). If not, the model
is retrieved from online sources and, by default, saved."><meta property="og:image" content="https://rimonim.github.io/embedplyr/logo.png"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">embedplyr</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/DDR.html">Distributed Dictionary Representation (DDR)</a></li>
  </ul></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Load Pretrained GloVe, word2vec, and fastText Embeddings</h1>

      <div class="d-none name"><code>load_embeddings.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Loads pretrained word embeddings. If the specified model has already been
downloaded, it is read from file with <code><a href="read_embeddings.html">read_embeddings()</a></code>. If not, the model
is retrieved from online sources and, by default, saved.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">load_embeddings</span><span class="op">(</span></span>
<span>  <span class="va">model</span>,</span>
<span>  dir <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  words <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  save <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  format <span class="op">=</span> <span class="st">"original"</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-model">model<a class="anchor" aria-label="anchor" href="#arg-model"></a></dt>
<dd><p>the name of a supported model</p></dd>


<dt id="arg-dir">dir<a class="anchor" aria-label="anchor" href="#arg-dir"></a></dt>
<dd><p>directory in which the model is or should be saved when <code>save = TRUE</code>.
The default is the working directory, <code><a href="https://rdrr.io/r/base/getwd.html" class="external-link">getwd()</a></code>. Dir can be set more
permanently using <code>options(embeddings.model.path = dir)</code>.</p></dd>


<dt id="arg-words">words<a class="anchor" aria-label="anchor" href="#arg-words"></a></dt>
<dd><p>optional list of words for which to retrieve embeddings.</p></dd>


<dt id="arg-save">save<a class="anchor" aria-label="anchor" href="#arg-save"></a></dt>
<dd><p>logical. Should the model be saved to <code>dir</code> if it does not
already exist there?</p></dd>


<dt id="arg-format">format<a class="anchor" aria-label="anchor" href="#arg-format"></a></dt>
<dd><p>the format in which the model should be saved if it does not
exist already. <code>"original"</code> (the default) saves the file as is.
Other options are <code>"csv"</code> or <code>"rds"</code>.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>The following are supported models for download. Note that some models are very large.
If you know in advance which word embeddings you will need (e.g. the set of unique
tokens in your corpus), consider specifying this with the <code>words</code> parameter to save
memory and processing time.</p><div class="section">
<h3 id="glove">GloVe<a class="anchor" aria-label="anchor" href="#glove"></a></h3>


<ul><li><p><code>glove.42B.300d</code>: Common Crawl (42B tokens, 1.9M vocab, uncased, 300d). Downloaded from https://huggingface.co/stanfordnlp/glove.
This file is a zip archive and must temporarily be downloaded in its entirety even when <code>words</code> is specified.</p></li>
<li><p><code>glove.840B.300d</code>: Common Crawl (840B tokens, 2.2M vocab, cased, 300d). Downloaded from https://huggingface.co/stanfordnlp/glove.
This file is a zip archive and must temporarily be downloaded in its entirety even when <code>words</code> is specified.</p></li>
<li><p><code>glove.6B.50d</code>: Wikipedia 2014 + Gigaword 5 (6B tokens, 400K vocab, uncased, 50d). Downloaded from https://github.com/piskvorky/gensim-data</p></li>
<li><p><code>glove.6B.100d</code>: Wikipedia 2014 + Gigaword 5 (6B tokens, 400K vocab, uncased, 100d). Downloaded from https://github.com/piskvorky/gensim-data</p></li>
<li><p><code>glove.6B.200d</code>: Wikipedia 2014 + Gigaword 5 (6B tokens, 400K vocab, uncased, 200d). Downloaded from https://github.com/piskvorky/gensim-data</p></li>
<li><p><code>glove.6B.300d</code>: Wikipedia 2014 + Gigaword 5 (6B tokens, 400K vocab, uncased, 300d). Downloaded from https://github.com/piskvorky/gensim-data</p></li>
<li><p><code>glove.twitter.27B.25d</code>: Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased, 25d). Downloaded from https://github.com/piskvorky/gensim-data</p></li>
<li><p><code>glove.twitter.27B.50d</code>: Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased, 50d). Downloaded from https://github.com/piskvorky/gensim-data</p></li>
<li><p><code>glove.twitter.27B.100d</code>: Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased, 100d). Downloaded from https://github.com/piskvorky/gensim-data</p></li>
<li><p><code>glove.twitter.27B.200d</code>: Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased, 200d). Downloaded from https://github.com/piskvorky/gensim-data</p></li>
</ul></div>

<div class="section">
<h3 id="word-vec">word2vec<a class="anchor" aria-label="anchor" href="#word-vec"></a></h3>


<p>Note that reading word2vec bin files may be slower than other formats. If
read time is a concern, consider setting <code>format = "csv"</code> or <code>format = "rds"</code>.</p><ul><li><p><code>GoogleNews.vectors.negative300</code>: Trained with skip-gram on Google News (~100B tokens, 3M vocab, cased, 300d). Downloaded from https://github.com/piskvorky/gensim-data</p></li>
</ul></div>

<div class="section">
<h3 id="conceptnet-numberbatch">ConceptNet Numberbatch<a class="anchor" aria-label="anchor" href="#conceptnet-numberbatch"></a></h3>


<p>Multilingual word embeddings trained using an ensemble that combines data from
word2vec, GloVe, OpenSubtitles, and the ConceptNet common sense knowledge database.
Tokens are prefixed with language codes. For example, the English word "token" is
labeled "/c/en/token".
Downloaded from https://github.com/commonsense/conceptnet-numberbatch</p><ul><li><p><code>numberbatch.19.08</code>: Multilingual (9.2M vocab, uncased, 300d)</p></li>
</ul></div>

<div class="section">
<h3 id="fasttext">fastText<a class="anchor" aria-label="anchor" href="#fasttext"></a></h3>


<p>300-dimensional word vectors for 157 languages, trained with CBOW on Common
Crawl and Wikipedia. Downloaded from https://fasttext.cc/docs/en/crawl-vectors.html</p><ul><li><p><code>cc.af.300</code>: Afrikaans</p></li>
<li><p><code>cc.sq.300</code>: Albanian</p></li>
<li><p><code>cc.als.300</code>: Alemannic</p></li>
<li><p><code>cc.am.300</code>: Amharic</p></li>
<li><p><code>cc.ar.300</code>: Arabic</p></li>
<li><p><code>cc.an.300</code>: Aragonese</p></li>
<li><p><code>cc.hy.300</code>: Armenian</p></li>
<li><p><code>cc.as.300</code>: Assamese</p></li>
<li><p><code>cc.ast.300</code>: Asturian</p></li>
<li><p><code>cc.az.300</code>: Azerbaijani</p></li>
<li><p><code>cc.ba.300</code>: Bashkir</p></li>
<li><p><code>cc.eu.300</code>: Basque</p></li>
<li><p><code>cc.bar.300</code>: Bavarian</p></li>
<li><p><code>cc.be.300</code>: Belarusian</p></li>
<li><p><code>cc.bn.300</code>: Bengali</p></li>
<li><p><code>cc.bh.300</code>: Bihari</p></li>
<li><p><code>cc.bpy.300</code>: Bishnupriya Manipuri</p></li>
<li><p><code>cc.bs.300</code>: Bosnian</p></li>
<li><p><code>cc.br.300</code>: Breton</p></li>
<li><p><code>cc.bg.300</code>: Bulgarian</p></li>
<li><p><code>cc.my.300</code>: Burmese</p></li>
<li><p><code>cc.ca.300</code>: Catalan</p></li>
<li><p><code>cc.ceb.300</code>: Cebuano</p></li>
<li><p><code>cc.bcl.300</code>: Central Bicolano</p></li>
<li><p><code>cc.ce.300</code>: Chechen</p></li>
<li><p><code>cc.zh.300</code>: Chinese</p></li>
<li><p><code>cc.cv.300</code>: Chuvash</p></li>
<li><p><code>cc.co.300</code>: Corsican</p></li>
<li><p><code>cc.hr.300</code>: Croatian</p></li>
<li><p><code>cc.cs.300</code>: Czech</p></li>
<li><p><code>cc.da.300</code>: Danish</p></li>
<li><p><code>cc.dv.300</code>: Divehi</p></li>
<li><p><code>cc.nl.300</code>: Dutch</p></li>
<li><p><code>cc.pa.300</code>: Eastern Punjabi</p></li>
<li><p><code>cc.arz.300</code>: Egyptian Arabic</p></li>
<li><p><code>cc.eml.300</code>: Emilian-Romagnol</p></li>
<li><p><code>cc.en.300</code>: English</p></li>
<li><p><code>cc.myv.300</code>: Erzya</p></li>
<li><p><code>cc.eo.300</code>: Esperanto</p></li>
<li><p><code>cc.et.300</code>: Estonian</p></li>
<li><p><code>cc.hif.300</code>: Fiji Hindi</p></li>
<li><p><code>cc.fi.300</code>: Finnish</p></li>
<li><p><code>cc.fr.300</code>: French</p></li>
<li><p><code>cc.gl.300</code>: Galician</p></li>
<li><p><code>cc.ka.300</code>: Georgian</p></li>
<li><p><code>cc.de.300</code>: German</p></li>
<li><p><code>cc.gom.300</code>: Goan Konkani</p></li>
<li><p><code>cc.el.300</code>: Greek</p></li>
<li><p><code>cc.gu.300</code>: Gujarati</p></li>
<li><p><code>cc.ht.300</code>: Haitian</p></li>
<li><p><code>cc.he.300</code>: Hebrew</p></li>
<li><p><code>cc.mrj.300</code>: Hill Mari</p></li>
<li><p><code>cc.hi.300</code>: Hindi</p></li>
<li><p><code>cc.hu.300</code>: Hungarian</p></li>
<li><p><code>cc.is.300</code>: Icelandic</p></li>
<li><p><code>cc.io.300</code>: Ido</p></li>
<li><p><code>cc.ilo.300</code>: Ilokano</p></li>
<li><p><code>cc.id.300</code>: Indonesian</p></li>
<li><p><code>cc.ia.300</code>: Interlingua</p></li>
<li><p><code>cc.ga.300</code>: Irish</p></li>
<li><p><code>cc.it.300</code>: Italian</p></li>
<li><p><code>cc.ja.300</code>: Japanese</p></li>
<li><p><code>cc.jv.300</code>: Javanese</p></li>
<li><p><code>cc.kn.300</code>: Kannada</p></li>
<li><p><code>cc.pam.300</code>: Kapampangan</p></li>
<li><p><code>cc.kk.300</code>: Kazakh</p></li>
<li><p><code>cc.km.300</code>: Khmer</p></li>
<li><p><code>cc.ky.300</code>: Kirghiz</p></li>
<li><p><code>cc.ko.300</code>: Korean</p></li>
<li><p><code>cc.ku.300</code>: Kurdish (Kurmanji)</p></li>
<li><p><code>cc.ckb.300</code>: Kurdish (Sorani)</p></li>
<li><p><code>cc.la.300</code>: Latin</p></li>
<li><p><code>cc.lv.300</code>: Latvian</p></li>
<li><p><code>cc.li.300</code>: Limburgish</p></li>
<li><p><code>cc.lt.300</code>: Lithuanian</p></li>
<li><p><code>cc.lmo.300</code>: Lombard</p></li>
<li><p><code>cc.nds.300</code>: Low Saxon</p></li>
<li><p><code>cc.lb.300</code>: Luxembourgish</p></li>
<li><p><code>cc.mk.300</code>: Macedonian</p></li>
<li><p><code>cc.mai.300</code>: Maithili</p></li>
<li><p><code>cc.mg.300</code>: Malagasy</p></li>
<li><p><code>cc.ms.300</code>: Malay</p></li>
<li><p><code>cc.ml.300</code>: Malayalam</p></li>
<li><p><code>cc.mt.300</code>: Maltese</p></li>
<li><p><code>cc.gv.300</code>: Manx</p></li>
<li><p><code>cc.mr.300</code>: Marathi</p></li>
<li><p><code>cc.mzn.300</code>: Mazandarani</p></li>
<li><p><code>cc.mhr.300</code>: Meadow Mari</p></li>
<li><p><code>cc.min.300</code>: Minangkabau</p></li>
<li><p><code>cc.xmf.300</code>: Mingrelian</p></li>
<li><p><code>cc.mwl.300</code>: Mirandese</p></li>
<li><p><code>cc.mn.300</code>: Mongolian</p></li>
<li><p><code>cc.nah.300</code>: Nahuatl</p></li>
<li><p><code>cc.nap.300</code>: Neapolitan</p></li>
<li><p><code>cc.ne.300</code>: Nepali</p></li>
<li><p><code>cc.new.300</code>: Newar</p></li>
<li><p><code>cc.frr.300</code>: North Frisian</p></li>
<li><p><code>cc.nso.300</code>: Northern Sotho</p></li>
<li><p><code>cc.no.300</code>: Norwegian (Bokmål)</p></li>
<li><p><code>cc.nn.300</code>: Norwegian (Nynorsk)</p></li>
<li><p><code>cc.oc.300</code>: Occitan</p></li>
<li><p><code>cc.or.300</code>: Oriya</p></li>
<li><p><code>cc.os.300</code>: Ossetian</p></li>
<li><p><code>cc.pfl.300</code>: Palatinate German</p></li>
<li><p><code>cc.ps.300</code>: Pashto</p></li>
<li><p><code>cc.fa.300</code>: Persian</p></li>
<li><p><code>cc.pms.300</code>: Piedmontese</p></li>
<li><p><code>cc.pl.300</code>: Polish</p></li>
<li><p><code>cc.pt.300</code>: Portuguese</p></li>
<li><p><code>cc.qu.300</code>: Quechua</p></li>
<li><p><code>cc.ro.300</code>: Romanian</p></li>
<li><p><code>cc.rm.300</code>: Romansh</p></li>
<li><p><code>cc.ru.300</code>: Russian</p></li>
<li><p><code>cc.sah.300</code>: Sakha</p></li>
<li><p><code>cc.sa.300</code>: Sanskrit</p></li>
<li><p><code>cc.sc.300</code>: Sardinian</p></li>
<li><p><code>cc.sco.300</code>: Scots</p></li>
<li><p><code>cc.gd.300</code>: Scottish Gaelic</p></li>
<li><p><code>cc.sr.300</code>: Serbian</p></li>
<li><p><code>cc.sh.300</code>: Serbo-Croatian</p></li>
<li><p><code>cc.scn.300</code>: Sicilian</p></li>
<li><p><code>cc.sd.300</code>: Sindhi</p></li>
<li><p><code>cc.si.300</code>: Sinhalese</p></li>
<li><p><code>cc.sk.300</code>: Slovak</p></li>
<li><p><code>cc.sl.300</code>: Slovenian</p></li>
<li><p><code>cc.so.300</code>: Somali</p></li>
<li><p><code>cc.azb.300</code>: Southern Azerbaijani</p></li>
<li><p><code>cc.es.300</code>: Spanish</p></li>
<li><p><code>cc.su.30</code>: Sundanese</p></li>
<li><p><code>cc.sw.300</code>: Swahili</p></li>
<li><p><code>cc.sv.300</code>: Swedish</p></li>
<li><p><code>cc.tl.300</code>: Tagalog</p></li>
<li><p><code>cc.tg.300</code>: Tajik</p></li>
<li><p><code>cc.ta.300</code>: Tamil</p></li>
<li><p><code>cc.tt.300</code>: Tatar</p></li>
<li><p><code>cc.te.300</code>: Telugu</p></li>
<li><p><code>cc.th.300</code>: Thai</p></li>
<li><p><code>cc.bo.300</code>: Tibetan</p></li>
<li><p><code>cc.tr.300</code>: Turkish</p></li>
<li><p><code>cc.tk.300</code>: Turkmen</p></li>
<li><p><code>cc.uk.300</code>: Ukrainian</p></li>
<li><p><code>cc.hsb.300</code>: Upper Sorbian</p></li>
<li><p><code>cc.ur.300</code>: Urdu</p></li>
<li><p><code>cc.ug.300</code>: Uyghur</p></li>
<li><p><code>cc.uz.300</code>: Uzbek</p></li>
<li><p><code>cc.vec.300</code>: Venetian</p></li>
<li><p><code>cc.vi.300</code>: Vietnamese</p></li>
<li><p><code>cc.vo.300</code>: Volapük</p></li>
<li><p><code>cc.wa.300</code>: Walloon</p></li>
<li><p><code>cc.war.300</code>: Waray</p></li>
<li><p><code>cc.cy.300</code>: Welsh</p></li>
<li><p><code>cc.vls.300</code>: West Flemish</p></li>
<li><p><code>cc.fy.300</code>: West Frisian</p></li>
<li><p><code>cc.pnb.300</code>: Western Punjabi</p></li>
<li><p><code>cc.yi.300</code>: Yiddish</p></li>
<li><p><code>cc.yo.300</code>: Yoruba</p></li>
<li><p><code>cc.diq.300</code>: Zazaki</p></li>
<li><p><code>cc.zea.300</code>: Zeelandic</p></li>
</ul></div>

    </div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>


<p>An embeddings object (a numeric matrix with tokens as rownames)</p>
    </div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>
    <p>Bojanowski, P., Grave, E., Joulin, A., and Mikolov, T. (2016). Enriching Word Vectors with Subword Information. arXiv preprint. https://arxiv.org/abs/1607.04606</p>
<p>Mikolov, T., Chen, K., Corrado, G., and Dean, J. (2013). Efficient Estimation of Word Representations in Vector Space. In Proceedings of Workshop at ICLR. https://arxiv.org/pdf/1301.3781</p>
<p>Pennington, J., Socher, R., and Manning, C. D. (2014). GloVe: Global Vectors for Word Representation. https://nlp.stanford.edu/projects/glove/</p>
<p>Speer, R., Chin, J., and Havasi, C. (2017). ConceptNet 5.5: An Open Multilingual Graph of General Knowledge. In proceedings of AAAI 2017. http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14972</p>
    </div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Louis Teitelbaum.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer></div>





  </body></html>

