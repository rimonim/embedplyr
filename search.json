[{"path":"https://rimonim.github.io/embedplyr/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://rimonim.github.io/embedplyr/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://rimonim.github.io/embedplyr/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://rimonim.github.io/embedplyr/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://rimonim.github.io/embedplyr/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://rimonim.github.io/embedplyr/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://rimonim.github.io/embedplyr/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://rimonim.github.io/embedplyr/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://rimonim.github.io/embedplyr/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://rimonim.github.io/embedplyr/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://rimonim.github.io/embedplyr/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://rimonim.github.io/embedplyr/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://rimonim.github.io/embedplyr/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://rimonim.github.io/embedplyr/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://rimonim.github.io/embedplyr/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://rimonim.github.io/embedplyr/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://rimonim.github.io/embedplyr/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://rimonim.github.io/embedplyr/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://rimonim.github.io/embedplyr/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://rimonim.github.io/embedplyr/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://rimonim.github.io/embedplyr/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://rimonim.github.io/embedplyr/articles/DDR.html","id":"load-word-embedding-model","dir":"Articles","previous_headings":"","what":"Load Word Embedding Model","title":"Distributed Dictionary Representation (DDR)","text":"","code":"glove_twitter_25d <- load_embeddings(\"glove.twitter.27B.25d\")"},{"path":"https://rimonim.github.io/embedplyr/articles/DDR.html","id":"embed-texts-of-interest","dir":"Articles","previous_headings":"","what":"Embed Texts of Interest","title":"Distributed Dictionary Representation (DDR)","text":"three example texts, can imagine written participant diagnosed depression, one diagnosed anxiety, one control. analyze extent texts reflect high vs low anxiety.","code":"psych_df <- tribble(     ~id,           ~text,     \"control\",     \"yesterday I took my dog for a walk\",     \"depression\",  \"I slept all day and cried in the evening\",     \"anxiety\",     \"I just kept thinking of all the things I needed to do\"     )  psych_embeddings_df <- psych_df |>      embed_docs(\"text\", glove_twitter_25d, id_col = \"id\", .keep_all = TRUE) #> Warning in predict.embeddings(model, feats, .keep_missing = TRUE): 1 items in #> `newdata` are not present in the embeddings object.  psych_embeddings_df #> # A tibble: 3 × 27 #>   id        text    dim_1 dim_2 dim_3   dim_4  dim_5   dim_6 dim_7  dim_8  dim_9 #>   <chr>     <chr>   <dbl> <dbl> <dbl>   <dbl>  <dbl>   <dbl> <dbl>  <dbl>  <dbl> #> 1 control   yest… -0.597  0.381 0.564  0.0372 -0.198 -0.143   1.11 -0.121 -0.290 #> 2 depressi… I sl… -0.547  0.195 0.472 -0.201  -0.372 -0.184   1.32 -0.270 -0.409 #> 3 anxiety   I ju… -0.0358 0.482 0.319 -0.105  -0.300 -0.0249  1.32 -0.471 -0.246 #> # ℹ 16 more variables: dim_10 <dbl>, dim_11 <dbl>, dim_12 <dbl>, dim_13 <dbl>, #> #   dim_14 <dbl>, dim_15 <dbl>, dim_16 <dbl>, dim_17 <dbl>, dim_18 <dbl>, #> #   dim_19 <dbl>, dim_20 <dbl>, dim_21 <dbl>, dim_22 <dbl>, dim_23 <dbl>, #> #   dim_24 <dbl>, dim_25 <dbl>"},{"path":"https://rimonim.github.io/embedplyr/articles/DDR.html","id":"load-and-embed-dictionaries","dir":"Articles","previous_headings":"","what":"Load and Embed Dictionaries","title":"Distributed Dictionary Representation (DDR)","text":"Many quality dictionaries available quanteda.sentiment sources (see DS4Psych, Chapter 14). sake example, use made-dictionaries.","code":"# positive and negative construct dictionaries high_anx_dict <- c(\"anxious\", \"overwhelmed\", \"exhausted\", \"nervous\", \"stressed\") low_anx_dict <- c(\"relaxed\", \"calm\", \"mellow\")  # embed dictionaries high_anx_dict_embeddings <- predict(glove_twitter_25d, high_anx_dict) #> Warning in predict.embeddings(glove_twitter_25d, high_anx_dict): 3 items in #> `newdata` are not present in the embeddings object. low_anx_dict_embeddings <- predict(glove_twitter_25d, low_anx_dict) #> Warning in predict.embeddings(glove_twitter_25d, low_anx_dict): 1 items in #> `newdata` are not present in the embeddings object.  # average embeddings to create DDR high_anx_DDR <- average_embedding(high_anx_dict_embeddings) low_anx_DDR <- average_embedding(low_anx_dict_embeddings)"},{"path":"https://rimonim.github.io/embedplyr/articles/DDR.html","id":"calculate-similarity-metrics","dir":"Articles","previous_headings":"","what":"Calculate Similarity Metrics","title":"Distributed Dictionary Representation (DDR)","text":"complete process, compare embeddings texts DDR. done computing cosine similarity text high_anx_DDR. since want know extent texts reflect high anxiety opposed low anxiety, use anchored vector. approach also known semantic projection (Grand et al., 2022). seems depression anxiety texts reflect quite bit anxiety control.","code":"anxiety_scores_df <- psych_embeddings_df |>    get_sims(     dim_1:dim_25,      list(anxiety = list(pos = high_anx_DDR, neg = low_anx_DDR)),     method = \"anchored\"     ) anxiety_scores_df #> # A tibble: 3 × 3 #>   id         text                                                  anxiety #>   <chr>      <chr>                                                   <dbl> #> 1 control    yesterday I took my dog for a walk                      0.127 #> 2 depression I slept all day and cried in the evening                0.162 #> 3 anxiety    I just kept thinking of all the things I needed to do   0.272"},{"path":"https://rimonim.github.io/embedplyr/articles/DDR.html","id":"weighted-ddr","dir":"Articles","previous_headings":"","what":"Weighted DDR","title":"Distributed Dictionary Representation (DDR)","text":"Garten et al. (2018) found DDR works best smaller dictionaries words directly connected construct measured (around 30 words worked best experiments). Word embeddings work overvaluing informative words (see DS4Psych, Chapter 18)—desirable property raw texts, uninformative words tend frequent. dictionaries include one word. longer dictionaries infrequent, tangentially connected words, averaging word embeddings therefore overvalue infrequent words skew DDR. can fixed Garten et al.’s method picking informative words. Alternatively, fixed measuring frequency dictionary word corpus weighting average embedding frequency. method consistent way dictionaries validated, counting frequencies dictionary words text (see DS4Psych, Chapter 14). absence reliable frequency data corpus (corpus dictionaries validated), can set w = \"trillion_word\" weight words frequencies Google Trillion Word corpus.","code":"# weighted averages high_anx_DDR_w <- average_embedding(high_anx_dict_embeddings, w = \"trillion_word\") low_anx_DDR_w <- average_embedding(low_anx_dict_embeddings, w = \"trillion_word\")  # calculate similarity scores anxiety_scores_df <- psych_embeddings_df |>    get_sims(     dim_1:dim_25,      list(anxiety = list(pos = high_anx_DDR_w, neg = low_anx_DDR_w)),     method = \"anchored\"     ) anxiety_scores_df #> # A tibble: 3 × 3 #>   id         text                                                  anxiety #>   <chr>      <chr>                                                   <dbl> #> 1 control    yesterday I took my dog for a walk                     0.0110 #> 2 depression I slept all day and cried in the evening               0.0909 #> 3 anxiety    I just kept thinking of all the things I needed to do  0.123"},{"path":"https://rimonim.github.io/embedplyr/articles/DDR.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Distributed Dictionary Representation (DDR)","text":"Garten, J., Hoover, J., Johnson, K. M., Boghrati, R., Iskiwitch, C., & Dehghani, M. (2018). Dictionaries distributions: Combining expert knowledge large scale textual data content analysis: Distributed dictionary representation. Behavior Research Methods, 50, 344–361. Grand, G., Blank, . ., Pereira, F., & Fedorenko, E. (2022). Semantic projection recovers rich human knowledge multiple object features word embeddings. Nature Human Behaviour, 6(7), 975–987.","code":""},{"path":"https://rimonim.github.io/embedplyr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Louis Teitelbaum. Maintainer, author, copyright holder.","code":""},{"path":"https://rimonim.github.io/embedplyr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Teitelbaum L (2024). embedplyr: Tools Working Text Embeddings. R package version 0.1.0, https://rimonim.github.io/embedplyr/.","code":"@Manual{,   title = {embedplyr: Tools for Working With Text Embeddings},   author = {Louis Teitelbaum},   year = {2024},   note = {R package version 0.1.0},   url = {https://rimonim.github.io/embedplyr/}, }"},{"path":[]},{"path":"https://rimonim.github.io/embedplyr/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Tools for Working With Text Embeddings","text":"embedplyr enables common operations word text embeddings within ‘tidyverse’ /‘quanteda’ workflow, demonstrated Data Science Psychology: Natural Language. load_embeddings() loads pretrained GloVe, word2vec, ConceptNet Numberbatch, fastText word embedding models Internet sources working directory embed_tokens() returns embedding token set texts embed_docs() generates text embeddings set documents get_sims() calculates row-wise similarity metrics set embeddings given reference average_embedding() calculates (weighted) average multiple embeddings reduce_dimensionality() reduces dimensionality embeddings normalize() normalize_rows() normalize embeddings unit hypersphere …","code":""},{"path":"https://rimonim.github.io/embedplyr/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Tools for Working With Text Embeddings","text":"can install development version embedplyr GitHub :","code":"remotes::install_github(\"rimonim/embedplyr\")"},{"path":"https://rimonim.github.io/embedplyr/index.html","id":"functionality","dir":"","previous_headings":"","what":"Functionality","title":"Tools for Working With Text Embeddings","text":"embedplyr designed facilitate use word text embeddings common data manipulation text analysis workflows, without introducing new syntax unfamiliar data structures. embedplyr model agnostic; can used work embeddings decontextualized models like GloVe word2vec, contextualized models like BERT others made available ‘text’ package.","code":""},{"path":"https://rimonim.github.io/embedplyr/index.html","id":"loading-pretrained-embeddings","dir":"","previous_headings":"Functionality","what":"Loading Pretrained Embeddings","title":"Tools for Working With Text Embeddings","text":"embedplyr won’t help train new embedding models, can load embeddings file download online. especially useful pretrained word embedding models like GloVe, word2vec, fastText. Dozens models can conveniently downloaded online sources load_embeddings(). outcome embeddings object. embeddings object just numeric matrix fast hash table indexing rownames (generally tokens). means can easily coerced dataframe tibble, also allowing special embeddings-specific methods functions, predict.embeddings() find_nearest(): Whereas indexing regular matrix rownames gets slower number rows increases, embedingplyr’s hash table indexing means token embeddings can retrieved milliseconds even models millions rows.","code":"library(embedplyr)  glove_twitter_25d <- load_embeddings(\"glove.twitter.27B.25d\") moral_embeddings <- predict(glove_twitter_25d, c(\"good\", \"bad\")) moral_embeddings #> # 25-dimensional embeddings with 2 rows #>      dim_1 dim_2 dim_3 dim_4 dim_5 dim_6 dim_7 dim_8 dim_9 dim..       #> good -0.54  0.60 -0.15 -0.02 -0.14  0.60  2.19  0.21 -0.52 -0.23 ...   #> bad   0.41  0.02  0.06 -0.01  0.27  0.71  1.64 -0.11 -0.26  0.11 ...  find_nearest(glove_twitter_25d, \"dog\", 5L, method = \"cosine\") #> # 25-dimensional embeddings with 5 rows #>        dim_1 dim_2 dim_3 dim_4 dim_5 dim_6 dim_7 dim_8 dim_9 dim..       #> dog    -1.24 -0.36  0.57  0.37  0.60 -0.19  1.27 -0.37  0.09  0.40 ...   #> cat    -0.96 -0.61  0.67  0.35  0.41 -0.21  1.38  0.13  0.32  0.66 ...   #> dogs   -0.63 -0.11  0.22  0.27  0.28  0.13  1.44 -1.18 -0.26  0.60 ...   #> horse  -0.76 -0.63  0.43  0.04  0.25 -0.18  1.08 -0.94  0.30  0.07 ...   #> monkey -0.96 -0.38  0.49  0.66  0.21 -0.09  1.28 -0.11  0.27  0.42 ..."},{"path":"https://rimonim.github.io/embedplyr/index.html","id":"similarity-metrics","dir":"","previous_headings":"Functionality","what":"Similarity Metrics","title":"Tools for Working With Text Embeddings","text":"Functions similarity distance metrics simple possible; one takes vectors outputs scalar.","code":"vec1 <- c(1, 5, 2) vec2 <- c(4, 2, 2) vec3 <- c(-1, -2, -13)  dot_prod(vec1, vec2)                        # dot product #> [1] 18 cos_sim(vec1, vec2)                         # cosine similarity #> [1] 0.6708204 euc_dist(vec1, vec2)                        # Euclidean distance #> [1] 4.242641 anchored_sim(vec1, pos = vec2, neg = vec3)  # projection to an anchored vector #> [1] 0.9887218"},{"path":"https://rimonim.github.io/embedplyr/index.html","id":"example-tidy-workflow","dir":"","previous_headings":"Functionality","what":"Example Tidy Workflow","title":"Tools for Working With Text Embeddings","text":"Given tidy dataframe texts, embed_docs() generate embeddings averaging embeddings words text (information works well, see Data Science Psychology, Chapter 18). default, embed_docs() uses simple unweighted mean, averaging methods available. embed_docs() can also used generate types embeddings. example, can use ‘text’ package generate embeddings using model available Huggingface transformers. quantify good intense texts , can compare embeddings “good” “intense” using get_sims(). Note step requires dataframe, tibble, embeddings object numeric columns; embeddings can come source.","code":"library(dplyr) valence_df <- tribble(     ~id,        ~text,     \"positive\", \"happy awesome cool nice\",     \"neutral\",  \"ok fine sure whatever\",     \"negative\", \"sad bad horrible angry\"     )  valence_embeddings_df <- valence_df |>      embed_docs(\"text\", glove_twitter_25d, id_col = \"id\", .keep_all = TRUE) valence_embeddings_df #> # A tibble: 3 × 27 #>   id       text       dim_1   dim_2    dim_3   dim_4   dim_5   dim_6 dim_7 dim_8 #>   <chr>    <chr>      <dbl>   <dbl>    <dbl>   <dbl>   <dbl>   <dbl> <dbl> <dbl> #> 1 positive happy a… -0.584  -0.0810 -0.00361 -0.381   0.0786  0.646   1.66 0.543 #> 2 neutral  ok fine… -0.0293  0.169  -0.226   -0.175  -0.389  -0.0313  1.22 0.222 #> 3 negative sad bad…  0.296  -0.244   0.150    0.0809  0.155   0.728   1.51 0.122 #> # ℹ 17 more variables: dim_9 <dbl>, dim_10 <dbl>, dim_11 <dbl>, dim_12 <dbl>, #> #   dim_13 <dbl>, dim_14 <dbl>, dim_15 <dbl>, dim_16 <dbl>, dim_17 <dbl>, #> #   dim_18 <dbl>, dim_19 <dbl>, dim_20 <dbl>, dim_21 <dbl>, dim_22 <dbl>, #> #   dim_23 <dbl>, dim_24 <dbl>, dim_25 <dbl> # function that takes character vector and outputs a data frame sbert_embeddings <- function(texts) {     text::textEmbed(         texts,         model = \"sentence-transformers/all-MiniLM-L12-v2\", # model name         layers = -2,  # second to last layer (default)         tokens_select = \"[CLS]\", # use only [CLS] token         dim_name = FALSE,         keep_token_embeddings = FALSE     )$texts[[1]] }  valence_sbert_df <- valence_df |>      embed_docs(\"text\", sbert_embeddings, id_col = \"id\", .keep_all = TRUE) good_vec <- predict(glove_twitter_25d, \"good\") intense_vec <- predict(glove_twitter_25d, \"intense\") valence_quantified <- valence_embeddings_df |>      get_sims(         dim_1:dim_25,          list(             good = good_vec,              intense = intense_vec             )         ) valence_quantified #> # A tibble: 3 × 4 #>   id       text                     good intense #>   <chr>    <chr>                   <dbl>   <dbl> #> 1 positive happy awesome cool nice 0.958   0.585 #> 2 neutral  ok fine sure whatever   0.909   0.535 #> 3 negative sad bad horrible angry  0.848   0.747"},{"path":"https://rimonim.github.io/embedplyr/index.html","id":"example-quanteda-workflow","dir":"","previous_headings":"Functionality","what":"Example Quanteda Workflow","title":"Tools for Working With Text Embeddings","text":"","code":"library(quanteda)  # corpus valence_corp <- corpus(valence_df, docid_field = \"id\") valence_corp #> Corpus consisting of 3 documents. #> positive : #> \"happy awesome cool nice\" #>  #> neutral : #> \"ok fine sure whatever\" #>  #> negative : #> \"sad bad horrible angry\"  # dfm valence_dfm <- valence_corp |>      tokens() |>      dfm()  # compute embeddings valence_embeddings_df <- valence_dfm |>      textstat_embedding(glove_twitter_25d) valence_embeddings_df #> # A tibble: 3 × 26 #>   doc_id     dim_1   dim_2    dim_3   dim_4   dim_5   dim_6 dim_7 dim_8  dim_9 #>   <chr>      <dbl>   <dbl>    <dbl>   <dbl>   <dbl>   <dbl> <dbl> <dbl>  <dbl> #> 1 positive -0.584  -0.0810 -0.00361 -0.381   0.0786  0.646   1.66 0.543 -0.830 #> 2 neutral  -0.0293  0.169  -0.226   -0.175  -0.389  -0.0313  1.22 0.222 -0.394 #> 3 negative  0.296  -0.244   0.150    0.0809  0.155   0.728   1.51 0.122 -0.588 #> # ℹ 16 more variables: dim_10 <dbl>, dim_11 <dbl>, dim_12 <dbl>, dim_13 <dbl>, #> #   dim_14 <dbl>, dim_15 <dbl>, dim_16 <dbl>, dim_17 <dbl>, dim_18 <dbl>, #> #   dim_19 <dbl>, dim_20 <dbl>, dim_21 <dbl>, dim_22 <dbl>, dim_23 <dbl>, #> #   dim_24 <dbl>, dim_25 <dbl>"},{"path":[]},{"path":"https://rimonim.github.io/embedplyr/index.html","id":"reduce-dimensionality","dir":"","previous_headings":"Functionality > Other Functions","what":"Reduce Dimensionality","title":"Tools for Working With Text Embeddings","text":"sometimes useful reduce dimensionality embeddings. done reduce_dimensionality(), default performs PCA without column normalization. reduce_dimensionality() can also used apply rotation embeddings used find principle components.","code":"valence_df_2d <- valence_embeddings_df |>      reduce_dimensionality(dim_1:dim_25, 2) valence_df_2d #> # A tibble: 3 × 3 #>   doc_id      PC1    PC2 #> * <chr>     <dbl>  <dbl> #> 1 positive -1.47   0.494 #> 2 neutral   0.121 -1.13  #> 3 negative  1.35   0.640 new_embeddings <- predict(glove_twitter_25d, c(\"new\", \"strange\"))  # get rotation with `output_rotation = TRUE` valence_rotation_2d <- valence_embeddings_df |>      reduce_dimensionality(dim_1:dim_25, 2, output_rotation = TRUE)  # apply the same rotation to new embeddings new_with_valence_rotation <- new_embeddings |>      reduce_dimensionality(custom_rotation = valence_rotation_2d) new_with_valence_rotation #> # 2-dimensional embeddings with 2 rows #>         PC1   PC2   #> new     -2.38  0.24 #> strange  0.09  1.18"},{"path":"https://rimonim.github.io/embedplyr/index.html","id":"normalize-scale-embeddings-to-the-unit-hypersphere","dir":"","previous_headings":"Functionality > Other Functions","what":"Normalize (Scale Embeddings to the Unit Hypersphere)","title":"Tools for Working With Text Embeddings","text":"normalize() normalize_rows() scale embeddings magnitude 1, angle origin unchanged.","code":"normalize(good_vec) #>        dim_1        dim_2        dim_3        dim_4        dim_5        dim_6  #> -0.090587846  0.100363800 -0.024215926 -0.003896062 -0.022930449  0.100135678  #>        dim_7        dim_8        dim_9       dim_10       dim_11       dim_12  #>  0.364995604  0.034641280 -0.085813930 -0.038466074 -0.133854478  0.094747331  #>       dim_13       dim_14       dim_15       dim_16       dim_17       dim_18  #> -0.836459360  0.044137493  0.079744546 -0.099664447  0.093466849 -0.181581983  #>       dim_19       dim_20       dim_21       dim_22       dim_23       dim_24  #> -0.087563977  0.020824065 -0.037671809  0.040843874 -0.076207818  0.154222299  #>       dim_25  #>  0.003684091  normalize(moral_embeddings) #> # 25-dimensional embeddings with 2 rows #>      dim_1 dim_2 dim_3 dim_4 dim_5 dim_6 dim_7 dim_8 dim_9 dim..       #> good -0.09  0.10 -0.02 -0.00 -0.02  0.10  0.36  0.03 -0.09 -0.04 ...   #> bad   0.08  0.00  0.01 -0.00  0.05  0.13  0.31 -0.02 -0.05  0.02 ...  valence_embeddings_df |> normalize_rows(dim_1:dim_25) #> # A tibble: 3 × 26 #>   doc_id    dim_1   dim_2    dim_3   dim_4   dim_5    dim_6 dim_7  dim_8   dim_9 #>   <chr>     <dbl>   <dbl>    <dbl>   <dbl>   <dbl>    <dbl> <dbl>  <dbl>   <dbl> #> 1 posit… -0.118   -0.0163 -7.26e-4 -0.0767  0.0158  0.130   0.334 0.109  -0.167  #> 2 neutr… -0.00633  0.0365 -4.87e-2 -0.0377 -0.0839 -0.00675 0.262 0.0479 -0.0850 #> 3 negat…  0.0666  -0.0549  3.38e-2  0.0182  0.0347  0.164   0.339 0.0274 -0.132  #> # ℹ 16 more variables: dim_10 <dbl>, dim_11 <dbl>, dim_12 <dbl>, dim_13 <dbl>, #> #   dim_14 <dbl>, dim_15 <dbl>, dim_16 <dbl>, dim_17 <dbl>, dim_18 <dbl>, #> #   dim_19 <dbl>, dim_20 <dbl>, dim_21 <dbl>, dim_22 <dbl>, dim_23 <dbl>, #> #   dim_24 <dbl>, dim_25 <dbl>"},{"path":"https://rimonim.github.io/embedplyr/index.html","id":"magnitude","dir":"","previous_headings":"Functionality > Other Functions","what":"Magnitude","title":"Tools for Working With Text Embeddings","text":"magnitude, norm, length vector Euclidean distance origin.","code":"magnitude(good_vec) #> [1] 6.005552  magnitude(moral_embeddings) #>     good      bad  #> 6.005552 5.355951"},{"path":"https://rimonim.github.io/embedplyr/reference/average_embedding.html","id":null,"dir":"Reference","previous_headings":"","what":"Average Embeddings — average_embedding","title":"Average Embeddings — average_embedding","text":"Calculate (weighted) average multiple embeddings.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/average_embedding.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Average Embeddings — average_embedding","text":"","code":"average_embedding(x, w = NULL, method = \"mean\", ...)"},{"path":"https://rimonim.github.io/embedplyr/reference/average_embedding.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Average Embeddings — average_embedding","text":"x embeddings object list embeddings objects w optional weighting rows x. can unnamed numeric vector one item per row x, named numeric vector length names match row names x, \"trillion_word\" (125,000 English word frequencies Peter Norvig's compilation, derived Google Web Trillion Word Corpus), \"trillion_word_sif\" smooth inverse frequencies (SIF) calculated using list. method method use averaging. \"mean\" (default) standard arithmetic mean. \"median\" geometric median (also called spatial median L1-median), computed using Gmedian::Gmedian() , weights provided, Gmedian::Weiszfeld(). \"sum\" (weighted) sum. ... additional arguments passed averaging function","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/average_embedding.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Average Embeddings — average_embedding","text":"w = \"trillion_word\" w = \"trillion_word_sif\", tokens appear word frequency list treated appeared often least frequent word list. w named vector, rows match items vector assigned minimum value vector.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/average_embedding.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Average Embeddings — average_embedding","text":"named numeric vector. x list, function called recursively output list length.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/average_embedding.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Average Embeddings — average_embedding","text":"","code":"happy_dict <- c(\"happy\", \"joy\", \"smile\", \"enjoy\") happy_dict_embeddings <- predict(glove_twitter_25d, happy_dict)  happy_dict_vec <- average_embedding(happy_dict_embeddings) happy_dict_vec_weighted <- average_embedding(happy_dict_embeddings, w = \"trillion_word\")  happy_dict_list <- find_nearest(glove_twitter_25d, happy_dict, each = TRUE) happy_dict_vec_list <- average_embedding(happy_dict_list)"},{"path":"https://rimonim.github.io/embedplyr/reference/build_token_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Build hash table to map tokens (i.e. doc_ids) to matrix indices — build_token_index","title":"Build hash table to map tokens (i.e. doc_ids) to matrix indices — build_token_index","text":"Build hash table map tokens (.e. doc_ids) matrix indices","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/build_token_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build hash table to map tokens (i.e. doc_ids) to matrix indices — build_token_index","text":"","code":"build_token_index(embeddings)"},{"path":"https://rimonim.github.io/embedplyr/reference/build_token_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build hash table to map tokens (i.e. doc_ids) to matrix indices — build_token_index","text":"embeddings embeddings object","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/embed_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Embeddings of Tokens in a Text or Corpus — embed_tokens","title":"Get Embeddings of Tokens in a Text or Corpus — embed_tokens","text":"Given character vector 'quanteda' object (tokens, dfm, corpus)  word embeddings model form embeddings object, embed_tokens() returns embedding token.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/embed_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Embeddings of Tokens in a Text or Corpus — embed_tokens","text":"","code":"embed_tokens(x, ...)  # Default S3 method embed_tokens(   x,   model,   ...,   .keep_missing = FALSE,   tolower = TRUE,   output_embeddings = FALSE )  # S3 method for class 'data.frame' embed_tokens(   x,   text_col,   model,   id_col = NULL,   ...,   .keep_missing = FALSE,   .keep_all = FALSE,   tolower = TRUE,   output_embeddings = FALSE )"},{"path":"https://rimonim.github.io/embedplyr/reference/embed_tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Embeddings of Tokens in a Text or Corpus — embed_tokens","text":"x character vector texts, data frame, 'quanteda' tokens object, 'quanteda' corpus ... additional parameters pass quanteda::tokens() model word embeddings model form embeddings object .keep_missing logical. done tokens x present model? FALSE (default), ignored. TRUE, returned NA. tolower logical. Convert text lowercase? output_embeddings FALSE (default) returns tibble. TRUE returns list embeddings objects. See 'Value' details. text_col string. column texts tokenized converted embeddings id_col optional string. column unique document ids .keep_all logical. Keep columns input? Ignored output_embeddings = TRUE.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/embed_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Embeddings of Tokens in a Text or Corpus — embed_tokens","text":"output_embeddings = FALSE, tibble columns doc_id, token, embedding dimension names. .keep_all = TRUE, new columns appear existing ones, class input maintained. output_embeddings = TRUE, named list embeddings objects tokens rownames.","code":""},{"path":[]},{"path":"https://rimonim.github.io/embedplyr/reference/embed_tokens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Embeddings of Tokens in a Text or Corpus — embed_tokens","text":"","code":"texts <- c(\"this says one thing\", \"and this says another\") texts_token_embeddings <- embed_tokens(texts, glove_twitter_25d) texts_token_embeddings #> # A tibble: 8 × 27 #>   doc_id token     dim_1   dim_2    dim_3   dim_4   dim_5   dim_6 dim_7  dim_8 #>   <chr>  <chr>     <dbl>   <dbl>    <dbl>   <dbl>   <dbl>   <dbl> <dbl>  <dbl> #> 1 text1  this    -0.179   0.384   0.0730  -0.324  -0.0924 -0.408  2.1   -0.114 #> 2 text1  says     0.0671  0.149  -0.0720  -0.278  -0.379  -1.40   0.968 -0.250 #> 3 text1  one      0.397   0.157   0.507   -0.0400 -0.118  -0.0116 1.77   0.335 #> 4 text1  thing    0.170  -0.0206  0.212    0.0643  0.392  -0.0448 2.23  -0.615 #> 5 text2  and     -0.812  -0.286   0.0625  -0.0369 -0.611  -0.156  1.62  -0.426 #> 6 text2  this    -0.179   0.384   0.0730  -0.324  -0.0924 -0.408  2.1   -0.114 #> 7 text2  says     0.0671  0.149  -0.0720  -0.278  -0.379  -1.40   0.968 -0.250 #> 8 text2  another -0.232   0.942  -0.00565  0.205   0.0913 -0.0198 1.63  -0.147 #> # ℹ 17 more variables: dim_9 <dbl>, dim_10 <dbl>, dim_11 <dbl>, dim_12 <dbl>, #> #   dim_13 <dbl>, dim_14 <dbl>, dim_15 <dbl>, dim_16 <dbl>, dim_17 <dbl>, #> #   dim_18 <dbl>, dim_19 <dbl>, dim_20 <dbl>, dim_21 <dbl>, dim_22 <dbl>, #> #   dim_23 <dbl>, dim_24 <dbl>, dim_25 <dbl>  # quanteda workflow library(quanteda) #> Package version: 4.1.0 #> Unicode version: 15.1 #> ICU version: 74.2 #> Parallel computing: disabled #> See https://quanteda.io for tutorials and examples. texts_tokens <- tokens(texts) texts_token_embeddings <- embed_tokens(texts_tokens, glove_twitter_25d) texts_token_embeddings #> # A tibble: 8 × 27 #>   doc_id token     dim_1   dim_2    dim_3   dim_4   dim_5   dim_6 dim_7  dim_8 #>   <chr>  <chr>     <dbl>   <dbl>    <dbl>   <dbl>   <dbl>   <dbl> <dbl>  <dbl> #> 1 text1  this    -0.179   0.384   0.0730  -0.324  -0.0924 -0.408  2.1   -0.114 #> 2 text1  says     0.0671  0.149  -0.0720  -0.278  -0.379  -1.40   0.968 -0.250 #> 3 text1  one      0.397   0.157   0.507   -0.0400 -0.118  -0.0116 1.77   0.335 #> 4 text1  thing    0.170  -0.0206  0.212    0.0643  0.392  -0.0448 2.23  -0.615 #> 5 text2  and     -0.812  -0.286   0.0625  -0.0369 -0.611  -0.156  1.62  -0.426 #> 6 text2  this    -0.179   0.384   0.0730  -0.324  -0.0924 -0.408  2.1   -0.114 #> 7 text2  says     0.0671  0.149  -0.0720  -0.278  -0.379  -1.40   0.968 -0.250 #> 8 text2  another -0.232   0.942  -0.00565  0.205   0.0913 -0.0198 1.63  -0.147 #> # ℹ 17 more variables: dim_9 <dbl>, dim_10 <dbl>, dim_11 <dbl>, dim_12 <dbl>, #> #   dim_13 <dbl>, dim_14 <dbl>, dim_15 <dbl>, dim_16 <dbl>, dim_17 <dbl>, #> #   dim_18 <dbl>, dim_19 <dbl>, dim_20 <dbl>, dim_21 <dbl>, dim_22 <dbl>, #> #   dim_23 <dbl>, dim_24 <dbl>, dim_25 <dbl>  # dplyr workflow texts_df <- data.frame(text = texts) texts_token_embeddings <- texts_df |> embed_tokens(\"text\", glove_twitter_25d) texts_token_embeddings #> # A tibble: 8 × 27 #>   doc_id token     dim_1   dim_2    dim_3   dim_4   dim_5   dim_6 dim_7  dim_8 #>   <chr>  <chr>     <dbl>   <dbl>    <dbl>   <dbl>   <dbl>   <dbl> <dbl>  <dbl> #> 1 text1  this    -0.179   0.384   0.0730  -0.324  -0.0924 -0.408  2.1   -0.114 #> 2 text1  says     0.0671  0.149  -0.0720  -0.278  -0.379  -1.40   0.968 -0.250 #> 3 text1  one      0.397   0.157   0.507   -0.0400 -0.118  -0.0116 1.77   0.335 #> 4 text1  thing    0.170  -0.0206  0.212    0.0643  0.392  -0.0448 2.23  -0.615 #> 5 text2  and     -0.812  -0.286   0.0625  -0.0369 -0.611  -0.156  1.62  -0.426 #> 6 text2  this    -0.179   0.384   0.0730  -0.324  -0.0924 -0.408  2.1   -0.114 #> 7 text2  says     0.0671  0.149  -0.0720  -0.278  -0.379  -1.40   0.968 -0.250 #> 8 text2  another -0.232   0.942  -0.00565  0.205   0.0913 -0.0198 1.63  -0.147 #> # ℹ 17 more variables: dim_9 <dbl>, dim_10 <dbl>, dim_11 <dbl>, dim_12 <dbl>, #> #   dim_13 <dbl>, dim_14 <dbl>, dim_15 <dbl>, dim_16 <dbl>, dim_17 <dbl>, #> #   dim_18 <dbl>, dim_19 <dbl>, dim_20 <dbl>, dim_21 <dbl>, dim_22 <dbl>, #> #   dim_23 <dbl>, dim_24 <dbl>, dim_25 <dbl>"},{"path":"https://rimonim.github.io/embedplyr/reference/embeddings-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for Embeddings Objects — rownames<-.embeddings","title":"Methods for Embeddings Objects — rownames<-.embeddings","text":"Functions modify rownames indices embeddings objects (e.g. unique, rbind, rownames<- etc.) behave usual matrices automatically updating hash table necessary. Functions coerce embeddings objects data types (e.g. .matrix) strip hash table attribute, leaving clean, familiar object.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/embeddings-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for Embeddings Objects — rownames<-.embeddings","text":"","code":"# S3 method for class 'embeddings' rownames(x) <- value  # S3 method for class 'embeddings' dimnames(x) <- value  # S3 method for class 'embeddings' unique(x, incomparables = FALSE, MARGIN = 1, fromLast = FALSE, ...)  # S3 method for class 'embeddings' t(x)  # S3 method for class 'embeddings' rbind(..., deparse.level = 1)  # S3 method for class 'embeddings' as.matrix(x, ...)  # S3 method for class 'embeddings' as_tibble(x, ..., rownames = NULL)"},{"path":"https://rimonim.github.io/embedplyr/reference/embeddings-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for Embeddings Objects — rownames<-.embeddings","text":"x embeddings object value valid value component     dimnames(x).  matrix array either     NULL character vector non-zero length equal     appropriate dimension. incomparables vector values compared.     FALSE special value, meaning values can     compared, may value accepted methods     default.  coerced internally type        x. MARGIN array margin held fixed: single integer. fromLast logical indicating duplication considered     last, .e., last (rightmost) identical elements     kept.  matters names     dimnames. ... rbind, embeddings objects objects coerced embeddings. Otherwise, arguments particular methods. deparse.level integer controlling construction labels     case non-matrix-like arguments (default method):deparse.level = 0 constructs labels;     default deparse.level = 1 typically     deparse.level = 2 always construct labels argument     names, see ‘Value’ section . rownames treat existing row names data frame matrix: NULL: remove row names. default. NA: keep row names. string: name new column. Existing rownames transferred column row.names attribute deleted. name repair applied new column name, even x already contains column name. Use as_tibble(rownames_to_column(...)) safeguard case. Read rownames.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/embeddings-subsetting.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract or Subset Parts of Embeddings Objects — [.embeddings","title":"Extract or Subset Parts of Embeddings Objects — [.embeddings","text":"Extraction, replacement, subsetting nearly identically matches behavior matrices, one exception: character item matches multiple rownames x, last match returned.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/embeddings-subsetting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract or Subset Parts of Embeddings Objects — [.embeddings","text":"","code":"# S3 method for class 'embeddings' x[i, j, drop = TRUE]  # S3 method for class 'embeddings' x[i, j] <- value  # S3 method for class 'embeddings' subset(x, subset, ...)"},{"path":"https://rimonim.github.io/embedplyr/reference/embeddings-subsetting.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract or Subset Parts of Embeddings Objects — [.embeddings","text":"x object subsetted. row index indices extract replace. Can numeric character. j column index indeces extract replace. Can numeric character. drop logical. TRUE (default) result one-dimensional (e.g. single row), output (named) vector. value typically numeric vector, matrix, embeddings object. subset logical expression indicating elements rows keep:     missing values taken false. ... arguments passed methods.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/embeddings-subsetting.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract or Subset Parts of Embeddings Objects — [.embeddings","text":"difference embeddings[,] predict(embeddings, ) former throw error items valid indices, whereas latter handle gracefully (cost milliseconds long).","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/embeddings-subsetting.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract or Subset Parts of Embeddings Objects — [.embeddings","text":"","code":"glove_twitter_25d[\"this\",] #>     dim_1     dim_2     dim_3     dim_4     dim_5     dim_6     dim_7     dim_8  #> -0.178950  0.384060  0.073035 -0.323630 -0.092441 -0.407670  2.100000 -0.113630  #>     dim_9    dim_10    dim_11    dim_12    dim_13    dim_14    dim_15    dim_16  #> -0.587840 -0.170340 -0.643300  0.723880 -5.783900 -0.104060  0.521520 -0.113140  #>    dim_17    dim_18    dim_19    dim_20    dim_21    dim_22    dim_23    dim_24  #>  0.595540 -0.475870 -0.455100  0.084431 -0.458200 -0.167270  0.545940  0.035478  #>    dim_25  #> -0.160730  glove_twitter_25d[c(\"this\", \"that\"),] #> # 25-dimensional embeddings with 2 rows #>      dim_1 dim_2 dim_3 dim_4 dim_5 dim_6 dim_7 dim_8 dim_9 dim..       #> this -0.18  0.38  0.07 -0.32 -0.09 -0.41  2.10 -0.11 -0.59 -0.17 ...   #> that  0.21  0.22 -0.07  0.24 -0.36 -0.23  1.86 -0.46 -0.41 -0.06 ...    glove_twitter_25d[1,] #>      dim_1      dim_2      dim_3      dim_4      dim_5      dim_6      dim_7  #> -0.0101670  0.0201940  0.2147300  0.1728900 -0.4365900 -0.1468700  1.8429000  #>      dim_8      dim_9     dim_10     dim_11     dim_12     dim_13     dim_14  #> -0.1575300  0.1818700 -0.3178200  0.0683900  0.5177600 -6.3371000  0.4806600  #>     dim_15     dim_16     dim_17     dim_18     dim_19     dim_20     dim_21  #>  0.1377700 -0.4856800  0.3900000 -0.0019506 -0.1021800  0.2126200 -0.8614600  #>     dim_22     dim_23     dim_24     dim_25  #>  0.1726300  0.1878300 -0.8425000 -0.3120800  glove_twitter_25d[1:10,] #> # 25-dimensional embeddings with 10 rows #>      dim_1 dim_2 dim_3 dim_4 dim_5 dim_6 dim_7 dim_8 dim_9 dim..       #> the  -0.01  0.02  0.21  0.17 -0.44 -0.15  1.84 -0.16  0.18 -0.32 ...   #> of    0.33 -0.09 -0.15  0.43 -0.09 -0.18  1.28 -0.60 -0.28 -0.05 ...   #> and  -0.81 -0.29  0.06 -0.04 -0.61 -0.16  1.62 -0.43  0.20 -0.19 ...   #> to    0.28  0.02  0.12 -0.39 -1.05 -0.54  1.14 -0.34  0.81 -0.47 ...   #> a     0.21  0.31  0.18  0.87  0.07  0.59 -0.10  1.59 -0.43 -1.37 ...   #> in   -0.33 -0.16  0.11 -0.40 -0.49 -0.18  0.23 -0.49 -0.07  0.84 ...   #> for  -0.22  0.45 -0.23 -0.28 -0.07 -0.64  1.12 -0.38  0.19 -0.51 ...   #> is   -0.13 -0.20 -0.13 -0.57 -0.30 -0.03  1.18 -0.15 -0.71 -0.12 ...   #> on    0.21 -0.24 -0.57  0.34 -0.86 -0.18  0.87 -0.11  0.53 -0.00 ...   #> that  0.21  0.22 -0.07  0.24 -0.36 -0.23  1.86 -0.46 -0.41 -0.06 ...    glove_twitter_25d[1] #> [1] -0.010167 glove_twitter_25d[1,1:10] #>     dim_1     dim_2     dim_3     dim_4     dim_5     dim_6     dim_7     dim_8  #> -0.010167  0.020194  0.214730  0.172890 -0.436590 -0.146870  1.842900 -0.157530  #>     dim_9    dim_10  #>  0.181870 -0.317820   duplicate_tokens <- embeddings(   1:15,   nrow = 3,   dimnames = list(c(\"this\", \"that\", \"this\"))   ) duplicate_tokens[\"this\",] #> dim_1 dim_2 dim_3 dim_4 dim_5  #>     3     6     9    12    15"},{"path":"https://rimonim.github.io/embedplyr/reference/embeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Embeddings Objects — embeddings","title":"Embeddings Objects — embeddings","text":"embeddings object numeric matrix fast indexing rownames (generally tokens).","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/embeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Embeddings Objects — embeddings","text":"","code":"embeddings(data = NA, nrow = 1, ncol = 1, byrow = FALSE, dimnames = NULL)  as.embeddings(x, ...)  # Default S3 method as.embeddings(x, ..., rowname_repair = TRUE, rebuild_token_index = TRUE)  # S3 method for class 'data.frame' as.embeddings(x, id_col = NULL, ..., rowname_repair = TRUE)  is.embeddings(x, ...)"},{"path":"https://rimonim.github.io/embedplyr/reference/embeddings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Embeddings Objects — embeddings","text":"data optional data vector (including list     expression vector).  Non-atomic classed R objects     coerced .vector attributes discarded. nrow desired number rows. ncol desired number columns. byrow logical. FALSE (default) matrix     filled columns, otherwise matrix filled rows. dimnames dimnames attribute matrix:     NULL list length 2 giving row column     names respectively.  empty list treated NULL,     list length one row names.  list can named,     list names used names dimensions. x data frame converted embeddings. ... Additional arguments passed methods. rowname_repair logical. TRUE (default), check unique rownames provided, name rows \"doc_1\", \"doc_2\", etc. . rebuild_token_index logical. TRUE, hash table index rebuilt even x embeddings object. id_col Optional name column take row names .","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/embeddings.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Embeddings Objects — embeddings","text":"Fast row indexing implemented using hash tables native R environments. \"token_index\" attribute embeddings object stores environment maps rownames corresponding indices. dimnames supplied, embeddings automatically name rows doc_1, doc_2, etc., columns dim_1, dim_2, etc.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/embeddings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Embeddings Objects — embeddings","text":"","code":"random_mat <- matrix(   sample(1:10, 20, replace = TRUE),   nrow = 2,   dimnames = list(c(\"happy\", \"sad\"))   ) random_embeddings <- as.embeddings(random_mat) is.embeddings(random_embeddings[,2:5]) #> [1] TRUE  tibble::as_tibble(random_embeddings, rownames = \"token\") #> # A tibble: 2 × 11 #>   token dim_1 dim_2 dim_3 dim_4 dim_5 dim_6 dim_7 dim_8 dim_9 dim_10 #>   <chr> <int> <int> <int> <int> <int> <int> <int> <int> <int>  <int> #> 1 happy     7     6     6     5     8     7     5     6     2      9 #> 2 sad       5     4     9     5     2     5     2     4     3      6"},{"path":"https://rimonim.github.io/embedplyr/reference/embedplyr-package.html","id":null,"dir":"Reference","previous_headings":"","what":"embedplyr: Tools for Working With Text Embeddings — embedplyr-package","title":"embedplyr: Tools for Working With Text Embeddings — embedplyr-package","text":"Common operations word text embeddings within 'tidyverse'/'quanteda' workflow, demonstrated \"Data Science Psychology: Natural Language\". Includes simple functions calculating common similarity metrics, well higher level functions loading pretrained word embedding models (e.g. 'GloVe'), applying words, aggregating produce text embeddings, reducing dimensionality.","code":""},{"path":[]},{"path":"https://rimonim.github.io/embedplyr/reference/embedplyr-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"embedplyr: Tools for Working With Text Embeddings — embedplyr-package","text":"Maintainer: Louis Teitelbaum louist@post.bgu.ac.il (ORCID) [copyright holder]","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/find_nearest.html","id":null,"dir":"Reference","previous_headings":"","what":"Find Nearest Tokens in Embedding Space — find_nearest","title":"Find Nearest Tokens in Embedding Space — find_nearest","text":"Find Nearest Tokens Embedding Space","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/find_nearest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find Nearest Tokens in Embedding Space — find_nearest","text":"","code":"find_nearest(   object,   newdata,   top_n = 10L,   method = c(\"cosine\", \"euclidean\", \"minkowski\", \"dot_prod\", \"anchored\"),   ...,   each = FALSE,   include_self = TRUE,   decreasing = NULL,   get_sims = FALSE )"},{"path":"https://rimonim.github.io/embedplyr/reference/find_nearest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find Nearest Tokens in Embedding Space — find_nearest","text":"object embeddings object made load_embeddings() .embeddings() newdata character vector tokens indexed object, embeddings object dimensionality object, numeric vector dimensionality object. top_n integer. many nearest neighbors output? = TRUE, many nearest neighbors output token? method either name method compute similarity distance, function takes two vectors outputs scalar, like listed Similarity Distance Metrics. value passed get_sims(). ... additional parameters passed method function way get_sims() logical. FALSE (default), embeddings newdata averaged function output embeddings object top_n nearest tokens overall average embedding. TRUE, function output named list one embeddings object token newdata. include_self logical. token(s) newdata included output? decreasing logical. Determines order sorting similarity scores. TRUE (default \"cosine\", \"dot_prod\", \"anchored\" methods), embeddings highest similarity scores output. FALSE (default \"euclidean\" \"minkowski\" methods), embeddings lowest distance scores output. get_sims logical. FALSE (default), output embeddings object list embeddings objects. TRUE, output tibble similarity distance scores document.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/find_nearest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find Nearest Tokens in Embedding Space — find_nearest","text":"get_sims = FALSE (default), embeddings object list embeddings objects.  get_sims = TRUE, tibble list tibbles similarity distance scores document, columns doc_id name requested method.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/find_nearest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find Nearest Tokens in Embedding Space — find_nearest","text":"","code":"words <- c(\"happy\", \"sad\") words_embeddings <- predict(glove_twitter_25d, words)  find_nearest(glove_twitter_25d, words) #> # 25-dimensional embeddings with 10 rows #>       dim_1 dim_2 dim_3 dim_4 dim_5 dim_6 dim_7 dim_8 dim_9 dim..       #> miss  -0.65  0.59  0.36  0.01 -1.05 -0.02  1.34  1.46 -0.84 -0.14 ...   #> happy -1.23  0.48  0.14 -0.03 -0.65 -0.19  2.10  1.75 -1.30 -0.32 ...   #> love  -0.63 -0.08  0.07  0.58 -0.87 -0.15  2.23  0.99 -1.32 -0.35 ...   #> wish  -0.52  1.12  0.49 -0.25 -1.01  0.38  2.00  0.56 -0.56  0.17 ...   #> you   -0.42  0.33 -0.09  0.20 -0.80 -0.34  2.14  0.37 -0.94  0.24 ...   #> thank -0.90  0.70 -0.06 -0.03 -0.77 -0.95  2.04  0.53 -1.30  0.07 ...   #> sad    0.04 -0.19  0.44 -0.15 -0.60  0.05  1.47  0.14 -0.72  0.43 ...   #> too   -0.47  0.40  0.12 -0.00 -0.21  0.46  1.68  0.08 -0.77  0.08 ...   #> good  -0.54  0.60 -0.15 -0.02 -0.14  0.60  2.19  0.21 -0.52 -0.23 ...   #> hope  -0.77  0.81  0.02 -0.23 -1.28 -0.31  1.83  0.19 -0.86 -0.23 ...   find_nearest(glove_twitter_25d, words_embeddings) # equivalent to previous #> # 25-dimensional embeddings with 10 rows #>       dim_1 dim_2 dim_3 dim_4 dim_5 dim_6 dim_7 dim_8 dim_9 dim..       #> miss  -0.65  0.59  0.36  0.01 -1.05 -0.02  1.34  1.46 -0.84 -0.14 ...   #> happy -1.23  0.48  0.14 -0.03 -0.65 -0.19  2.10  1.75 -1.30 -0.32 ...   #> love  -0.63 -0.08  0.07  0.58 -0.87 -0.15  2.23  0.99 -1.32 -0.35 ...   #> wish  -0.52  1.12  0.49 -0.25 -1.01  0.38  2.00  0.56 -0.56  0.17 ...   #> you   -0.42  0.33 -0.09  0.20 -0.80 -0.34  2.14  0.37 -0.94  0.24 ...   #> thank -0.90  0.70 -0.06 -0.03 -0.77 -0.95  2.04  0.53 -1.30  0.07 ...   #> sad    0.04 -0.19  0.44 -0.15 -0.60  0.05  1.47  0.14 -0.72  0.43 ...   #> too   -0.47  0.40  0.12 -0.00 -0.21  0.46  1.68  0.08 -0.77  0.08 ...   #> good  -0.54  0.60 -0.15 -0.02 -0.14  0.60  2.19  0.21 -0.52 -0.23 ...   #> hope  -0.77  0.81  0.02 -0.23 -1.28 -0.31  1.83  0.19 -0.86 -0.23 ...   find_nearest(glove_twitter_25d, words, each = TRUE) #> $happy #> # 25-dimensional embeddings with 10 rows #>          dim_1 dim_2 dim_3 dim_4 dim_5 dim_6 dim_7 dim_8 dim_9       #> happy    -1.23  0.48  0.14 -0.03 -0.65 -0.19  2.10  1.75 -1.30 ...   #> birthday -1.46  0.50  1.00  0.17 -0.68 -0.75  1.82  1.55 -1.24 ...   #> thank    -0.90  0.70 -0.06 -0.03 -0.77 -0.95  2.04  0.53 -1.30 ...   #> welcome  -0.97  0.88 -0.25 -0.54 -0.55 -0.44  1.46  0.78 -0.70 ...   #> love     -0.63 -0.08  0.07  0.58 -0.87 -0.15  2.23  0.99 -1.32 ...   #> miss     -0.65  0.59  0.36  0.01 -1.05 -0.02  1.34  1.46 -0.84 ...   #> hello    -0.77  0.13  0.33  0.01 -0.48 -0.50  1.86  1.06 -0.57 ...   #> thanks   -0.80  0.82 -0.28 -0.11 -0.55 -0.72  1.62  0.98 -1.00 ...   #> merry    -1.23  0.56  0.37  0.41 -0.56 -0.65  1.62  0.36 -1.62 ...   #> bless    -1.15  0.81 -0.26  0.77 -0.68 -0.82  1.40  0.55 -1.23 ...   #>  #> $sad #> # 25-dimensional embeddings with 10 rows #>          dim_1 dim_2 dim_3 dim_4 dim_5 dim_6 dim_7 dim_8 dim_9       #> sad       0.04 -0.19  0.44 -0.15 -0.60  0.05  1.47  0.14 -0.72 ...   #> feel     -0.33  0.07  0.15 -0.17 -0.26  0.94  2.28 -0.17 -1.04 ...   #> same      0.53  0.30  0.47 -0.02 -0.00  0.33  1.30 -0.05 -0.15 ...   #> wrong     0.68  0.45  0.26  0.38 -0.06 -0.02  1.36 -0.64 -0.65 ...   #> meant     0.22  0.20  0.17 -0.26 -0.68 -0.37  1.32 -0.92 -0.92 ...   #> true      0.40  0.02 -0.63  0.04 -0.01  0.11  1.84  0.55 -0.94 ...   #> reason    0.44  0.42 -0.00  0.33 -0.09  0.02  1.87 -0.57 -0.62 ...   #> remember  0.12  0.77  0.56  0.20 -0.91 -0.26  1.93 -0.02 -0.87 ...   #> i        -0.26  0.59  0.62 -0.70 -0.85 -0.23  1.05  0.07 -0.55 ...   #> know      0.30  0.70 -0.00 -0.06 -0.69 -0.14  1.95  0.01 -0.51 ...   #>  find_nearest(glove_twitter_25d, words_embeddings, each = TRUE) # equivalent to previous #> $happy #> # 25-dimensional embeddings with 10 rows #>          dim_1 dim_2 dim_3 dim_4 dim_5 dim_6 dim_7 dim_8 dim_9       #> happy    -1.23  0.48  0.14 -0.03 -0.65 -0.19  2.10  1.75 -1.30 ...   #> birthday -1.46  0.50  1.00  0.17 -0.68 -0.75  1.82  1.55 -1.24 ...   #> thank    -0.90  0.70 -0.06 -0.03 -0.77 -0.95  2.04  0.53 -1.30 ...   #> welcome  -0.97  0.88 -0.25 -0.54 -0.55 -0.44  1.46  0.78 -0.70 ...   #> love     -0.63 -0.08  0.07  0.58 -0.87 -0.15  2.23  0.99 -1.32 ...   #> miss     -0.65  0.59  0.36  0.01 -1.05 -0.02  1.34  1.46 -0.84 ...   #> hello    -0.77  0.13  0.33  0.01 -0.48 -0.50  1.86  1.06 -0.57 ...   #> thanks   -0.80  0.82 -0.28 -0.11 -0.55 -0.72  1.62  0.98 -1.00 ...   #> merry    -1.23  0.56  0.37  0.41 -0.56 -0.65  1.62  0.36 -1.62 ...   #> bless    -1.15  0.81 -0.26  0.77 -0.68 -0.82  1.40  0.55 -1.23 ...   #>  #> $sad #> # 25-dimensional embeddings with 10 rows #>          dim_1 dim_2 dim_3 dim_4 dim_5 dim_6 dim_7 dim_8 dim_9       #> sad       0.04 -0.19  0.44 -0.15 -0.60  0.05  1.47  0.14 -0.72 ...   #> feel     -0.33  0.07  0.15 -0.17 -0.26  0.94  2.28 -0.17 -1.04 ...   #> same      0.53  0.30  0.47 -0.02 -0.00  0.33  1.30 -0.05 -0.15 ...   #> wrong     0.68  0.45  0.26  0.38 -0.06 -0.02  1.36 -0.64 -0.65 ...   #> meant     0.22  0.20  0.17 -0.26 -0.68 -0.37  1.32 -0.92 -0.92 ...   #> true      0.40  0.02 -0.63  0.04 -0.01  0.11  1.84  0.55 -0.94 ...   #> reason    0.44  0.42 -0.00  0.33 -0.09  0.02  1.87 -0.57 -0.62 ...   #> remember  0.12  0.77  0.56  0.20 -0.91 -0.26  1.93 -0.02 -0.87 ...   #> i        -0.26  0.59  0.62 -0.70 -0.85 -0.23  1.05  0.07 -0.55 ...   #> know      0.30  0.70 -0.00 -0.06 -0.69 -0.14  1.95  0.01 -0.51 ...   #>   rand_vec <- rnorm(25) find_nearest(glove_twitter_25d, rand_vec) #> # 25-dimensional embeddings with 10 rows #>               dim_1 dim_2 dim_3 dim_4 dim_5 dim_6 dim_7 dim_8       #> entertaining   0.23  0.27  0.07 -0.65  0.83  1.09  1.24 -1.42 ...   #> nervous       -0.45  0.17  0.21 -0.80  0.24  0.89  1.91 -0.57 ...   #> relaxed       -1.93 -0.55 -0.63 -0.43  0.51  2.03  0.29 -1.48 ...   #> enjoyable     -0.66  0.07 -0.23 -0.63  0.48  1.29  1.63 -1.73 ...   #> surprisingly  -0.62 -0.56  0.19 -1.03  0.09  1.68  0.99 -1.63 ...   #> instructors   -0.74  0.91 -0.14 -1.04  0.85 -0.20 -0.08 -1.92 ...   #> routines      -0.21  0.42 -0.04 -0.30  1.11  0.45  0.69 -2.46 ...   #> productive    -0.85  0.68 -0.40 -0.81  0.97  1.20  1.38 -1.74 ...   #> philosophical -0.43  0.11 -0.77  0.93  1.00  1.50  1.02 -1.77 ...   #> sgt            0.47 -0.89 -0.43 -1.23 -0.24  2.14 -0.43  1.63 ..."},{"path":"https://rimonim.github.io/embedplyr/reference/format.embeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Formatting and Printing for Embeddings Objects — format.embeddings","title":"Formatting and Printing for Embeddings Objects — format.embeddings","text":"Since numerical content embeddings generally informative naked eye, default formatting matrices often cumbersome. , embeddings objects print format allows quick visualization dimensionality row names.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/format.embeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Formatting and Printing for Embeddings Objects — format.embeddings","text":"","code":"# S3 method for class 'embeddings' format(x, ..., n = NULL, round = 2L)"},{"path":"https://rimonim.github.io/embedplyr/reference/format.embeddings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Formatting and Printing for Embeddings Objects — format.embeddings","text":"x embeddings object formatted ... arguments passed methods n integer. many rows printed? Defaults 10. value can permanently customized setting options(embeddings.print.n = n). round integer. number decimal places displayed","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/format.embeddings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Formatting and Printing for Embeddings Objects — format.embeddings","text":"","code":"print(glove_twitter_25d, n = 5) #> # 25-dimensional embeddings with 11925 rows #>     dim_1 dim_2 dim_3 dim_4 dim_5 dim_6 dim_7 dim_8 dim_9 dim..       #> the -0.01  0.02  0.21  0.17 -0.44 -0.15  1.84 -0.16  0.18 -0.32 ...   #> of   0.33 -0.09 -0.15  0.43 -0.09 -0.18  1.28 -0.60 -0.28 -0.05 ...   #> and -0.81 -0.29  0.06 -0.04 -0.61 -0.16  1.62 -0.43  0.20 -0.19 ...   #> to   0.28  0.02  0.12 -0.39 -1.05 -0.54  1.14 -0.34  0.81 -0.47 ...   #> a    0.21  0.31  0.18  0.87  0.07  0.59 -0.10  1.59 -0.43 -1.37 ..."},{"path":"https://rimonim.github.io/embedplyr/reference/get_sims.html","id":null,"dir":"Reference","previous_headings":"","what":"Row-wise Similarity and Distance Metrics — get_sims","title":"Row-wise Similarity and Distance Metrics — get_sims","text":"get_sims(df, col1:col2, list(sim = vec2)) essentially equivalent mutate(rowwise(df), sim = cos_sim(c_across(col1:col2), vec2)). Includes methods dataframes (style dplyr), embeddings objects, matrices.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/get_sims.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Row-wise Similarity and Distance Metrics — get_sims","text":"","code":"get_sims(x, ...)  # S3 method for class 'embeddings' get_sims(   x,   y,   method = c(\"cosine\", \"cosine_squished\", \"euclidean\", \"minkowski\", \"dot_prod\",     \"anchored\"),   ... )  # S3 method for class 'data.frame' get_sims(   x,   cols,   y,   method = c(\"cosine\", \"cosine_squished\", \"euclidean\", \"minkowski\", \"dot_prod\",     \"anchored\"),   ...,   .keep_all = \"except.embeddings\" )"},{"path":"https://rimonim.github.io/embedplyr/reference/get_sims.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Row-wise Similarity and Distance Metrics — get_sims","text":"x embeddings object, matrix, dataframe one embedding per row ... additional parameters passed method function y named list vectors dimensionality embeddings x. item result column output, showing similarity embedding x vector specified y. method = \"anchored\", item y list named vectors pos neg. method either name method compute similarity distance, function takes two vectors, x y, outputs scalar, similar listed Similarity Distance Metrics cols tidyselect - columns contain numeric embedding values .keep_all TRUE, columns input retained output. FALSE, similarity metrics included. \"except.embeddings\" (default), columns except used compute similarity retained.","code":""},{"path":[]},{"path":"https://rimonim.github.io/embedplyr/reference/get_sims.html","id":"available-methods","dir":"Reference","previous_headings":"","what":"Available Methods","title":"Row-wise Similarity and Distance Metrics — get_sims","text":"method name one following supported methods, computations done matrix operations therefore blazing fast. cosine: cosine similarity cosine_squished: cosine similarity, rescaled range 0 1 euclidean: Euclidean distance minkowski: Minkowski distance; requires parameter p. p = 1 (default), Manhattan distance. p = 2, Euclidean distance. p = Inf, Chebyshev distance. dot_prod: Dot product anchored: x projected onto range two anchor points, vectors aligned pos given score 1 aligned neg given score 0. anchored vectors, see Data Science Psychology: Natural Language, Chapter 20. method custom function, operations performed row may slow large inputs.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/get_sims.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Row-wise Similarity and Distance Metrics — get_sims","text":"tibble columns doc_id, similarity metrics. .keep_all = TRUE .keep_all = \"except.embeddings\", new columns appear existing ones.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/get_sims.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Row-wise Similarity and Distance Metrics — get_sims","text":"","code":"valence_embeddings <- predict(glove_twitter_25d, c(\"good\", \"bad\")) happy_vec <- predict(glove_twitter_25d, \"happy\") sad_vec <- predict(glove_twitter_25d, \"sad\")  valence_embeddings |>   get_sims(list(happy = happy_vec)) #> # A tibble: 2 × 2 #>   doc_id happy #>   <chr>  <dbl> #> 1 good   0.883 #> 2 bad    0.707 valence_embeddings |>   get_sims(     list(happy = list(pos = happy_vec, neg = sad_vec)),     anchored_sim     ) #> # A tibble: 2 × 2 #>   doc_id happy #>   <chr>  <dbl> #> 1 good   0.601 #> 2 bad    0.106 valence_embeddings |>   get_sims(     list(happy = happy_vec),     method = function(x, y) sum(abs(x - y))     ) #> # A tibble: 2 × 2 #>   doc_id happy #>   <chr>  <dbl> #> 1 good    9.70 #> 2 bad    17.0   valence_df <- tibble::as_tibble(valence_embeddings, rownames = \"token\") valence_df |> get_sims(   dim_1:dim_25,   list(happy = happy_vec, sad = sad_vec),   .keep_all = TRUE   ) #> # A tibble: 2 × 28 #>   token  dim_1  dim_2   dim_3   dim_4  dim_5 dim_6 dim_7  dim_8  dim_9 dim_10 #>   <chr>  <dbl>  <dbl>   <dbl>   <dbl>  <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl> #> 1 good  -0.544 0.603  -0.145  -0.0234 -0.138 0.601  2.19  0.208 -0.515 -0.231 #> 2 bad    0.414 0.0223  0.0565 -0.0105  0.274 0.713  1.64 -0.112 -0.262  0.108 #> # ℹ 17 more variables: dim_11 <dbl>, dim_12 <dbl>, dim_13 <dbl>, dim_14 <dbl>, #> #   dim_15 <dbl>, dim_16 <dbl>, dim_17 <dbl>, dim_18 <dbl>, dim_19 <dbl>, #> #   dim_20 <dbl>, dim_21 <dbl>, dim_22 <dbl>, dim_23 <dbl>, dim_24 <dbl>, #> #   dim_25 <dbl>, happy <dbl>, sad <dbl>"},{"path":"https://rimonim.github.io/embedplyr/reference/glove_twitter_25d.html","id":null,"dir":"Reference","previous_headings":"","what":"25-d GloVe Model Pretrained on Twitter (subset) — glove_twitter_25d","title":"25-d GloVe Model Pretrained on Twitter (subset) — glove_twitter_25d","text":"embeddings object containing subset glove.twitter.25d pretrained Pennington et al. (2014) 2B Tweets. subset includes embeddings included 12,000 common English words, defined Peter Norvig's compilation, derived Google Web Trillion Word Corpus. Full pretrained GloVe models available download https://nlp.stanford.edu/projects/glove/","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/glove_twitter_25d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"25-d GloVe Model Pretrained on Twitter (subset) — glove_twitter_25d","text":"","code":"glove_twitter_25d"},{"path":"https://rimonim.github.io/embedplyr/reference/glove_twitter_25d.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"25-d GloVe Model Pretrained on Twitter (subset) — glove_twitter_25d","text":"object class embeddings (inherits matrix, array) 11925 rows 25 columns.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/glove_twitter_25d.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"25-d GloVe Model Pretrained on Twitter (subset) — glove_twitter_25d","text":"Pennington, J., Socher, R., Manning, C. D. (2014). GloVe: Global Vectors Word Representation. https://nlp.stanford.edu/projects/glove/","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/is_matrixlike.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if an object is matrix-like and numeric — is_matrixlike","title":"Check if an object is matrix-like and numeric — is_matrixlike","text":"Check object matrix-like numeric","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/is_matrixlike.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if an object is matrix-like and numeric — is_matrixlike","text":"","code":"is_matrixlike(x)"},{"path":"https://rimonim.github.io/embedplyr/reference/is_matrixlike.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if an object is matrix-like and numeric — is_matrixlike","text":"x object checked","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/load_embeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Load Pretrained GloVe, word2vec, and fastText Embeddings — load_embeddings","title":"Load Pretrained GloVe, word2vec, and fastText Embeddings — load_embeddings","text":"Loads pretrained word embeddings. specified model already downloaded, read file read_embeddings(). , model retrieved online sources , default, saved.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/load_embeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load Pretrained GloVe, word2vec, and fastText Embeddings — load_embeddings","text":"","code":"load_embeddings(   model,   dir = NULL,   words = NULL,   save = TRUE,   format = \"original\" )"},{"path":"https://rimonim.github.io/embedplyr/reference/load_embeddings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load Pretrained GloVe, word2vec, and fastText Embeddings — load_embeddings","text":"model name supported model dir directory model saved save = TRUE. default working directory, getwd(). Dir can set permanently using options(embeddings.model.path = dir). words optional list words retrieve embeddings. save logical. model saved dir already exist ? format format model saved exist already. \"original\" (default) saves file . options \"csv\" \"rds\".","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/load_embeddings.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Load Pretrained GloVe, word2vec, and fastText Embeddings — load_embeddings","text":"following supported models download. Note models large. know advance word embeddings need (e.g. set unique tokens corpus), consider specifying words parameter save memory processing time.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/load_embeddings.html","id":"glove","dir":"Reference","previous_headings":"","what":"GloVe","title":"Load Pretrained GloVe, word2vec, and fastText Embeddings — load_embeddings","text":"glove.42B.300d: Common Crawl (42B tokens, 1.9M vocab, uncased, 300d). Downloaded https://huggingface.co/stanfordnlp/glove. file zip archive must temporarily downloaded entirety even words specified. glove.840B.300d: Common Crawl (840B tokens, 2.2M vocab, cased, 300d). Downloaded https://huggingface.co/stanfordnlp/glove. file zip archive must temporarily downloaded entirety even words specified. glove.6B.50d: Wikipedia 2014 + Gigaword 5 (6B tokens, 400K vocab, uncased, 50d). Downloaded https://github.com/piskvorky/gensim-data glove.6B.100d: Wikipedia 2014 + Gigaword 5 (6B tokens, 400K vocab, uncased, 100d). Downloaded https://github.com/piskvorky/gensim-data glove.6B.200d: Wikipedia 2014 + Gigaword 5 (6B tokens, 400K vocab, uncased, 200d). Downloaded https://github.com/piskvorky/gensim-data glove.6B.300d: Wikipedia 2014 + Gigaword 5 (6B tokens, 400K vocab, uncased, 300d). Downloaded https://github.com/piskvorky/gensim-data glove.twitter.27B.25d: Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased, 25d). Downloaded https://github.com/piskvorky/gensim-data glove.twitter.27B.50d: Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased, 50d). Downloaded https://github.com/piskvorky/gensim-data glove.twitter.27B.100d: Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased, 100d). Downloaded https://github.com/piskvorky/gensim-data glove.twitter.27B.200d: Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased, 200d). Downloaded https://github.com/piskvorky/gensim-data","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/load_embeddings.html","id":"word-vec","dir":"Reference","previous_headings":"","what":"word2vec","title":"Load Pretrained GloVe, word2vec, and fastText Embeddings — load_embeddings","text":"Note reading word2vec bin files may slower formats. read time concern, consider setting format = \"csv\" format = \"rds\". GoogleNews.vectors.negative300: Trained skip-gram Google News (~100B tokens, 3M vocab, cased, 300d). Downloaded https://github.com/piskvorky/gensim-data","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/load_embeddings.html","id":"conceptnet-numberbatch","dir":"Reference","previous_headings":"","what":"ConceptNet Numberbatch","title":"Load Pretrained GloVe, word2vec, and fastText Embeddings — load_embeddings","text":"Multilingual word embeddings trained using ensemble combines data word2vec, GloVe, OpenSubtitles, ConceptNet common sense knowledge database. Tokens prefixed language codes. example, English word \"token\" labeled \"/c/en/token\". Downloaded https://github.com/commonsense/conceptnet-numberbatch numberbatch.19.08: Multilingual (9.2M vocab, uncased, 300d)","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/load_embeddings.html","id":"fasttext","dir":"Reference","previous_headings":"","what":"fastText","title":"Load Pretrained GloVe, word2vec, and fastText Embeddings — load_embeddings","text":"300-dimensional word vectors 157 languages, trained CBOW Common Crawl Wikipedia. Downloaded https://fasttext.cc/docs/en/crawl-vectors.html cc.af.300: Afrikaans cc.sq.300: Albanian cc.als.300: Alemannic cc..300: Amharic cc.ar.300: Arabic cc..300: Aragonese cc.hy.300: Armenian cc..300: Assamese cc.ast.300: Asturian cc.az.300: Azerbaijani cc.ba.300: Bashkir cc.eu.300: Basque cc.bar.300: Bavarian cc..300: Belarusian cc.bn.300: Bengali cc.bh.300: Bihari cc.bpy.300: Bishnupriya Manipuri cc.bs.300: Bosnian cc.br.300: Breton cc.bg.300: Bulgarian cc..300: Burmese cc.ca.300: Catalan cc.ceb.300: Cebuano cc.bcl.300: Central Bicolano cc.ce.300: Chechen cc.zh.300: Chinese cc.cv.300: Chuvash cc.co.300: Corsican cc.hr.300: Croatian cc.cs.300: Czech cc.da.300: Danish cc.dv.300: Divehi cc.nl.300: Dutch cc.pa.300: Eastern Punjabi cc.arz.300: Egyptian Arabic cc.eml.300: Emilian-Romagnol cc.en.300: English cc.myv.300: Erzya cc.eo.300: Esperanto cc.et.300: Estonian cc.hif.300: Fiji Hindi cc.fi.300: Finnish cc.fr.300: French cc.gl.300: Galician cc.ka.300: Georgian cc.de.300: German cc.gom.300: Goan Konkani cc.el.300: Greek cc.gu.300: Gujarati cc.ht.300: Haitian cc..300: Hebrew cc.mrj.300: Hill Mari cc.hi.300: Hindi cc.hu.300: Hungarian cc..300: Icelandic cc.io.300: Ido cc.ilo.300: Ilokano cc.id.300: Indonesian cc.ia.300: Interlingua cc.ga.300: Irish cc..300: Italian cc.ja.300: Japanese cc.jv.300: Javanese cc.kn.300: Kannada cc.pam.300: Kapampangan cc.kk.300: Kazakh cc.km.300: Khmer cc.ky.300: Kirghiz cc.ko.300: Korean cc.ku.300: Kurdish (Kurmanji) cc.ckb.300: Kurdish (Sorani) cc.la.300: Latin cc.lv.300: Latvian cc.li.300: Limburgish cc.lt.300: Lithuanian cc.lmo.300: Lombard cc.nds.300: Low Saxon cc.lb.300: Luxembourgish cc.mk.300: Macedonian cc.mai.300: Maithili cc.mg.300: Malagasy cc.ms.300: Malay cc.ml.300: Malayalam cc.mt.300: Maltese cc.gv.300: Manx cc.mr.300: Marathi cc.mzn.300: Mazandarani cc.mhr.300: Meadow Mari cc.min.300: Minangkabau cc.xmf.300: Mingrelian cc.mwl.300: Mirandese cc.mn.300: Mongolian cc.nah.300: Nahuatl cc.nap.300: Neapolitan cc.ne.300: Nepali cc.new.300: Newar cc.frr.300: North Frisian cc.nso.300: Northern Sotho cc..300: Norwegian (Bokmål) cc.nn.300: Norwegian (Nynorsk) cc.oc.300: Occitan cc..300: Oriya cc.os.300: Ossetian cc.pfl.300: Palatinate German cc.ps.300: Pashto cc.fa.300: Persian cc.pms.300: Piedmontese cc.pl.300: Polish cc.pt.300: Portuguese cc.qu.300: Quechua cc.ro.300: Romanian cc.rm.300: Romansh cc.ru.300: Russian cc.sah.300: Sakha cc.sa.300: Sanskrit cc.sc.300: Sardinian cc.sco.300: Scots cc.gd.300: Scottish Gaelic cc.sr.300: Serbian cc.sh.300: Serbo-Croatian cc.scn.300: Sicilian cc.sd.300: Sindhi cc.si.300: Sinhalese cc.sk.300: Slovak cc.sl.300: Slovenian cc..300: Somali cc.azb.300: Southern Azerbaijani cc.es.300: Spanish cc.su.30: Sundanese cc.sw.300: Swahili cc.sv.300: Swedish cc.tl.300: Tagalog cc.tg.300: Tajik cc.ta.300: Tamil cc.tt.300: Tatar cc.te.300: Telugu cc.th.300: Thai cc.bo.300: Tibetan cc.tr.300: Turkish cc.tk.300: Turkmen cc.uk.300: Ukrainian cc.hsb.300: Upper Sorbian cc.ur.300: Urdu cc.ug.300: Uyghur cc.uz.300: Uzbek cc.vec.300: Venetian cc.vi.300: Vietnamese cc.vo.300: Volapük cc.wa.300: Walloon cc.war.300: Waray cc.cy.300: Welsh cc.vls.300: West Flemish cc.fy.300: West Frisian cc.pnb.300: Western Punjabi cc.yi.300: Yiddish cc.yo.300: Yoruba cc.diq.300: Zazaki cc.zea.300: Zeelandic","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/load_embeddings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load Pretrained GloVe, word2vec, and fastText Embeddings — load_embeddings","text":"embeddings object (numeric matrix tokens rownames)","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/load_embeddings.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Load Pretrained GloVe, word2vec, and fastText Embeddings — load_embeddings","text":"Bojanowski, P., Grave, E., Joulin, ., Mikolov, T. (2016). Enriching Word Vectors Subword Information. arXiv preprint. https://arxiv.org/abs/1607.04606 Mikolov, T., Chen, K., Corrado, G., Dean, J. (2013). Efficient Estimation Word Representations Vector Space. Proceedings Workshop ICLR. https://arxiv.org/pdf/1301.3781 Pennington, J., Socher, R., Manning, C. D. (2014). GloVe: Global Vectors Word Representation. https://nlp.stanford.edu/projects/glove/ Speer, R., Chin, J., Havasi, C. (2017). ConceptNet 5.5: Open Multilingual Graph General Knowledge. proceedings AAAI 2017. http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14972","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/magnitude.html","id":null,"dir":"Reference","previous_headings":"","what":"Magnitude of Embeddings — magnitude","title":"Magnitude of Embeddings — magnitude","text":"magnitude, norm, length vector Euclidean distance origin.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/magnitude.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Magnitude of Embeddings — magnitude","text":"","code":"magnitude(x, ...)  # S3 method for class 'numeric' magnitude(x, ...)"},{"path":"https://rimonim.github.io/embedplyr/reference/magnitude.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Magnitude of Embeddings — magnitude","text":"x numeric vector, embeddings object, list numeric embeddings objects ... additional parameters passed methods","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/magnitude.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Magnitude of Embeddings — magnitude","text":"numeric vector one item per embedding x. x list, function called recursively return list.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/magnitude.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Magnitude of Embeddings — magnitude","text":"","code":"vec <- c(1, 4, 2) magnitude(vec) #> [1] 4.582576  valence_embeddings <- predict(glove_twitter_25d, c(\"good\", \"bad\")) magnitude(valence_embeddings) #>     good      bad  #> 6.005552 5.355951   embeddings_list <- find_nearest(glove_twitter_25d, c(\"good\", \"bad\"), each = TRUE) magnitude(embeddings_list) #> $good #>     good      too      day     well     nice   better      fun     much  #> 6.005552 5.813283 5.802194 5.721374 5.194440 5.865108 5.015976 5.993338  #>     this     hope  #> 6.427068 5.640379  #>  #> $bad #>      bad     shit    crazy      but     hell    right     like     same  #> 5.355951 6.304527 5.171107 6.335841 5.225420 5.881975 6.027912 5.545610  #>     damn    thing  #> 5.610414 5.674697  #>"},{"path":"https://rimonim.github.io/embedplyr/reference/normalize.html","id":null,"dir":"Reference","previous_headings":"","what":"Scale Embeddings to the Unit Hypersphere — normalize","title":"Scale Embeddings to the Unit Hypersphere — normalize","text":"Normalize embeddings magnitude 1, angle origin unchanged.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/normalize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scale Embeddings to the Unit Hypersphere — normalize","text":"","code":"normalize(x, ...)  # S3 method for class 'numeric' normalize(x, ...)  normalize_rows(x, ...)  # Default S3 method normalize_rows(x, ...)  # S3 method for class 'data.frame' normalize_rows(x, cols, ...)"},{"path":"https://rimonim.github.io/embedplyr/reference/normalize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scale Embeddings to the Unit Hypersphere — normalize","text":"x normalize(), numeric vector, embeddings object, list numeric embeddings objects. normalize_rows(), matrix dataframe one embedding per row. ... additional parameters passed methods cols tidyselect - columns contain numeric embedding values","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/normalize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scale Embeddings to the Unit Hypersphere — normalize","text":"object class dimensionality x","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/normalize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scale Embeddings to the Unit Hypersphere — normalize","text":"","code":"vec <- c(1, 4, 2) normalize(vec) #> [1] 0.2182179 0.8728716 0.4364358  valence_embeddings <- predict(glove_twitter_25d, c(\"good\", \"bad\")) normalize(valence_embeddings) #> # 25-dimensional embeddings with 2 rows #>      dim_1 dim_2 dim_3 dim_4 dim_5 dim_6 dim_7 dim_8 dim_9 dim..       #> good -0.09  0.10 -0.02 -0.00 -0.02  0.10  0.36  0.03 -0.09 -0.04 ...   #> bad   0.08  0.00  0.01 -0.00  0.05  0.13  0.31 -0.02 -0.05  0.02 ...    embeddings_list <- find_nearest(glove_twitter_25d, c(\"good\", \"bad\"), each = TRUE) normalize(embeddings_list) #> $good #> # 25-dimensional embeddings with 10 rows #>        dim_1 dim_2 dim_3 dim_4 dim_5 dim_6 dim_7 dim_8 dim_9 dim..       #> good   -0.09  0.10 -0.02 -0.00 -0.02  0.10  0.36  0.03 -0.09 -0.04 ...   #> too    -0.08  0.07  0.02 -0.00 -0.04  0.08  0.29  0.01 -0.13  0.01 ...   #> day    -0.16  0.09  0.06 -0.07 -0.01 -0.03  0.39  0.04 -0.08 -0.03 ...   #> well   -0.01  0.04 -0.02 -0.11 -0.12  0.03  0.29 -0.05 -0.14  0.02 ...   #> nice   -0.15 -0.02 -0.01 -0.03  0.03  0.19  0.26  0.00 -0.17  0.02 ...   #> better -0.02  0.12 -0.02 -0.05 -0.06  0.11  0.27 -0.04 -0.06 -0.07 ...   #> fun    -0.13  0.10  0.03 -0.10  0.06  0.15  0.41 -0.03 -0.10 -0.00 ...   #> much   -0.04  0.03 -0.04  0.02 -0.06  0.03  0.31 -0.03 -0.25 -0.02 ...   #> this   -0.03  0.06  0.01 -0.05 -0.01 -0.06  0.33 -0.02 -0.09 -0.03 ...   #> hope   -0.14  0.14  0.00 -0.04 -0.23 -0.06  0.32  0.03 -0.15 -0.04 ...   #>  #> $bad #> # 25-dimensional embeddings with 10 rows #>       dim_1 dim_2 dim_3 dim_4 dim_5 dim_6 dim_7 dim_8 dim_9 dim..       #> bad    0.08  0.00  0.01 -0.00  0.05  0.13  0.31 -0.02 -0.05  0.02 ...   #> shit   0.11  0.12  0.07  0.02  0.05  0.11  0.20 -0.04 -0.11  0.07 ...   #> crazy -0.02  0.06  0.10 -0.05  0.07  0.17  0.33  0.00 -0.15 -0.04 ...   #> but    0.03 -0.00 -0.05 -0.03 -0.09  0.03  0.28 -0.10 -0.08  0.02 ...   #> hell   0.04  0.09  0.09  0.01 -0.05  0.06  0.29 -0.05 -0.11  0.09 ...   #> right -0.07  0.02  0.00 -0.02 -0.01 -0.01  0.30 -0.08 -0.08  0.08 ...   #> like   0.01  0.02  0.10  0.06 -0.05  0.07  0.29 -0.00 -0.11  0.03 ...   #> same   0.09  0.05  0.09 -0.00 -0.00  0.06  0.24 -0.01 -0.03  0.12 ...   #> damn   0.04  0.13  0.11 -0.01  0.00  0.13  0.28  0.00 -0.12  0.11 ...   #> thing  0.03 -0.00  0.04  0.01  0.07 -0.01  0.39 -0.11 -0.10 -0.03 ...   #>   valence_df <- tibble::as_tibble(valence_embeddings, rownames = \"token\") valence_df |> normalize_rows(dim_1:dim_25) #> # A tibble: 2 × 26 #>   token   dim_1   dim_2   dim_3    dim_4   dim_5 dim_6 dim_7   dim_8   dim_9 #>   <chr>   <dbl>   <dbl>   <dbl>    <dbl>   <dbl> <dbl> <dbl>   <dbl>   <dbl> #> 1 good  -0.0906 0.100   -0.0242 -0.00390 -0.0229 0.100 0.365  0.0346 -0.0858 #> 2 bad    0.0773 0.00417  0.0106 -0.00196  0.0511 0.133 0.306 -0.0209 -0.0490 #> # ℹ 16 more variables: dim_10 <dbl>, dim_11 <dbl>, dim_12 <dbl>, dim_13 <dbl>, #> #   dim_14 <dbl>, dim_15 <dbl>, dim_16 <dbl>, dim_17 <dbl>, dim_18 <dbl>, #> #   dim_19 <dbl>, dim_20 <dbl>, dim_21 <dbl>, dim_22 <dbl>, dim_23 <dbl>, #> #   dim_24 <dbl>, dim_25 <dbl>"},{"path":"https://rimonim.github.io/embedplyr/reference/predict.embeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve Token Embeddings — predict.embeddings","title":"Retrieve Token Embeddings — predict.embeddings","text":"Retrieve Token Embeddings","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/predict.embeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve Token Embeddings — predict.embeddings","text":"","code":"# S3 method for class 'embeddings' predict(object, newdata, drop = TRUE, .keep_missing = FALSE)"},{"path":"https://rimonim.github.io/embedplyr/reference/predict.embeddings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve Token Embeddings — predict.embeddings","text":"object embeddings object made load_embeddings() .embeddings() newdata character vector tokens drop logical. TRUE (default) result one-dimensional (e.g. single row), output (named) vector. .keep_missing logical. done items newdata present embeddings object? FALSE (default), ignored. TRUE, returned NA.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/predict.embeddings.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Retrieve Token Embeddings — predict.embeddings","text":"Duplicated items newdata result duplicated rows output. item newdata matches multiple rows object, last one returned.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/predict.embeddings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve Token Embeddings — predict.embeddings","text":"Either embeddings object row item newdata, , newdata length 1, named numeric vector.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/predict.embeddings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve Token Embeddings — predict.embeddings","text":"","code":"words <- c(\"happy\", \"sad\")  texts_embeddings <- predict(glove_twitter_25d, words) texts_embeddings #> # 25-dimensional embeddings with 2 rows #>       dim_1 dim_2 dim_3 dim_4 dim_5 dim_6 dim_7 dim_8 dim_9 dim..       #> happy -1.23  0.48  0.14 -0.03 -0.65 -0.19  2.10  1.75 -1.30 -0.32 ...   #> sad    0.04 -0.19  0.44 -0.15 -0.60  0.05  1.47  0.14 -0.72  0.43 ..."},{"path":"https://rimonim.github.io/embedplyr/reference/project_points_onto_line.html","id":null,"dir":"Reference","previous_headings":"","what":"Additional Vector Utilities — project_points_onto_line","title":"Additional Vector Utilities — project_points_onto_line","text":"Additional Vector Utilities","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/project_points_onto_line.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Additional Vector Utilities — project_points_onto_line","text":"","code":"project_points_onto_line(points, line_start, line_end)"},{"path":"https://rimonim.github.io/embedplyr/reference/project_points_onto_line.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Additional Vector Utilities — project_points_onto_line","text":"points dataframe, matrix, embeddings object row represents coordinates point projected onto line line_start vector representing coordinates line's start line_end vector representing coordinates line's end","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/project_points_onto_line.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Additional Vector Utilities — project_points_onto_line","text":"project_points_onto_line calculated projections group points onto line defined two end points. useful graphing positions embeddings respect anchored vector.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/project_points_onto_line.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Additional Vector Utilities — project_points_onto_line","text":"","code":"emotion_words <- c(\"happy\", \"sad\", \"scared\", \"angry\", \"anxious\", \"grateful\") emotion_embeddings <- predict(glove_twitter_25d, emotion_words) #> Warning: 1 items in `newdata` are not present in the embeddings object. emotion_embeddings_2d <- reduce_dimensionality(emotion_embeddings, 2)  # project points happy_vec_2d <- predict(emotion_embeddings_2d, \"happy\") sad_vec_2d <- predict(emotion_embeddings_2d, \"sad\") emotional_projections <- emotion_embeddings_2d |>   project_points_onto_line(happy_vec_2d, sad_vec_2d)"},{"path":"https://rimonim.github.io/embedplyr/reference/read_embeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Read Embeddings From a Text or Binary File — read_embeddings","title":"Read Embeddings From a Text or Binary File — read_embeddings","text":"Reads GloVe text format, fastText text format, word2vec binary format, tabular formats (csv, tsv, etc.)","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/read_embeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read Embeddings From a Text or Binary File — read_embeddings","text":"","code":"read_embeddings(path, words = NULL)"},{"path":"https://rimonim.github.io/embedplyr/reference/read_embeddings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read Embeddings From a Text or Binary File — read_embeddings","text":"path file path url words optional list words retrieve embeddings.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/read_embeddings.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read Embeddings From a Text or Binary File — read_embeddings","text":"using custom tabular format, file must tokens first column numbers columns.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/read_embeddings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read Embeddings From a Text or Binary File — read_embeddings","text":"embeddings object (numeric matrix tokens rownames)","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/reduce_dimensionality.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduce the Dimensionality of Embeddings — reduce_dimensionality","title":"Reduce the Dimensionality of Embeddings — reduce_dimensionality","text":"Includes methods dataframes (style dplyr), embeddings objects, matrices.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/reduce_dimensionality.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduce the Dimensionality of Embeddings — reduce_dimensionality","text":"","code":"reduce_dimensionality(x, ...)  # S3 method for class 'data.frame' reduce_dimensionality(   x,   cols,   reduce_to = NULL,   center = TRUE,   scale = FALSE,   tol = NULL,   ...,   custom_rotation = NULL,   output_rotation = FALSE )  # S3 method for class 'embeddings' reduce_dimensionality(   x,   reduce_to = NULL,   center = TRUE,   scale = FALSE,   tol = NULL,   ...,   custom_rotation = NULL,   output_rotation = FALSE )"},{"path":"https://rimonim.github.io/embedplyr/reference/reduce_dimensionality.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduce the Dimensionality of Embeddings — reduce_dimensionality","text":"x embeddings object dataframe one embedding per row, list objects ... additional parameters passed class-specific methods cols tidyselect - columns contain numeric embedding values reduce_to number dimensions keep. value passed stats::prcomp() rank.. center logical. dimensions shifted centered zero? scale logical. dimensions scaled unit variance? tol value indicating magnitude dimensions omitted. (Components omitted standard deviations less equal tol times standard deviation first component.) Value passed stats::prcomp(). custom_rotation optional rotation specification obtained calling function output_rotation = TRUE. override reduce_to, center, scale, instead simply apply custom rotation. output_rotation TRUE outputs rotation specification can applied embeddings","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/reduce_dimensionality.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reduce the Dimensionality of Embeddings — reduce_dimensionality","text":"default, reduce_dimensionality(), performs principle components analysis (PCA) without column normalization, outputs rotated data. center = FALSE scale = FALSE, equivalent singular value decomposition (SVD), \\(X = U \\Sigma V^{T}\\), output columns equal first reduce_to columns \\(U \\Sigma\\) meet criterion set tol.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/reduce_dimensionality.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reduce the Dimensionality of Embeddings — reduce_dimensionality","text":"output_rotation = FALSE, object class x, number rows fewer columns. Reduced columns output named \"PC1\", \"PC2\", etc. output_rotation = TRUE, list following components: rotation: rotation matrix center: vector describing much offset dimension match centering x scale: vector standard deviation column x x list, function called recursively output list length.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/reduce_dimensionality.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reduce the Dimensionality of Embeddings — reduce_dimensionality","text":"","code":"glove_2d <- reduce_dimensionality(glove_twitter_25d, 2) glove_2d #> # 2-dimensional embeddings with 11925 rows #>      PC1   PC2   #> the  -3.51  0.93 #> of   -2.90  1.29 #> and  -3.35  1.15 #> to   -3.64  0.77 #> a    -3.77 -1.05 #> in   -3.16  0.37 #> for  -3.09  0.83 #> is   -3.52  0.99 #> on   -3.36  0.00 #> that -3.79  1.92  embeddings_list <- find_nearest(glove_twitter_25d, c(\"good\", \"bad\"), each = TRUE) embeddings_list_2d <- reduce_dimensionality(embeddings_list, 2) embeddings_list_2d #> $good #> # 2-dimensional embeddings with 10 rows #>        PC1   PC2   #> good   -0.33 -0.02 #> too     0.36  0.78 #> day    -1.15 -1.07 #> well    0.81  0.38 #> nice   -1.04  1.22 #> better  0.85  0.15 #> fun    -1.45  0.07 #> much    0.91  0.21 #> this    0.39 -1.26 #> hope    0.64 -0.46 #>  #> $bad #> # 2-dimensional embeddings with 10 rows #>       PC1   PC2   #> bad   -0.03 -0.28 #> shit  -1.01  0.06 #> crazy -0.70  0.23 #> but    1.40  0.31 #> hell  -0.95  0.32 #> right  0.43  0.94 #> like   0.13  0.22 #> same   0.71 -1.33 #> damn  -1.12 -0.50 #> thing  1.13  0.03 #>   library(tibble) glove_tbl <- as_tibble(glove_twitter_25d, rownames = \"token\") glove_tbl_2d <- glove_tbl |> reduce_dimensionality(dim_1:dim_25, 2) glove_tbl_2d #> # A tibble: 11,925 × 3 #>    token   PC1      PC2 #>  * <chr> <dbl>    <dbl> #>  1 the   -3.51  0.926   #>  2 of    -2.90  1.29    #>  3 and   -3.35  1.15    #>  4 to    -3.64  0.773   #>  5 a     -3.77 -1.05    #>  6 in    -3.16  0.370   #>  7 for   -3.09  0.831   #>  8 is    -3.52  0.987   #>  9 on    -3.36  0.00238 #> 10 that  -3.79  1.92    #> # ℹ 11,915 more rows"},{"path":"https://rimonim.github.io/embedplyr/reference/sim_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Pairwise Similarity or Distance Matrix — sim_matrix","title":"Pairwise Similarity or Distance Matrix — sim_matrix","text":"Calculate matrix similarity scores rows input.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/sim_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pairwise Similarity or Distance Matrix — sim_matrix","text":"","code":"sim_matrix(x, ...)  # S3 method for class 'data.frame' sim_matrix(   x,   cols,   method = c(\"cosine\", \"cosine_squished\", \"euclidean\", \"minkowski\", \"dot_prod\",     \"anchored\"),   ...,   tidy_output = FALSE )"},{"path":"https://rimonim.github.io/embedplyr/reference/sim_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pairwise Similarity or Distance Matrix — sim_matrix","text":"x embeddings object, matrix, dataframe one embedding per row ... additional parameters passed method function cols tidyselect - columns contain numeric embedding values method either name method compute similarity distance, function takes two vectors, x y, outputs scalar, similar listed Similarity Distance Metrics tidy_output logical. FALSE (default), output stats::dist object. TRUE, output tibble columns doc_id_1, doc_id_2, similarity distance metric.","code":""},{"path":[]},{"path":"https://rimonim.github.io/embedplyr/reference/sim_matrix.html","id":"available-methods","dir":"Reference","previous_headings":"","what":"Available Methods","title":"Pairwise Similarity or Distance Matrix — sim_matrix","text":"method name one following supported methods, computations done matrix operations therefore blazing fast. cosine: cosine similarity cosine_squished: cosine similarity, rescaled range 0 1 euclidean: Euclidean distance minkowski: Minkowski distance; requires parameter p. p = 1 (default), Manhattan distance. p = 2, Euclidean distance. p = Inf, Chebyshev distance. dot_prod: Dot product method custom function, operations performed row may slow large inputs.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/sim_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pairwise Similarity or Distance Matrix — sim_matrix","text":"tidy_output = FALSE (default), stats::dist object. tidy_output = TRUE, tibble columns doc_id_1, doc_id_2, similarity distance metric.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/sim_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pairwise Similarity or Distance Matrix — sim_matrix","text":"","code":"emb <- predict(glove_twitter_25d, c(\"table\", \"chair\", \"cat\"))  sim_matrix(emb) #>           table     chair #> chair 0.8680218           #> cat   0.7297673 0.7455769 sim_matrix(emb, method = \"euclidean\") #>          table    chair #> chair 2.421414          #> cat   3.300149 3.286518 sim_matrix(emb, method = function(x, y) sum(abs(x - y))) #>          table    chair #> chair 10.33815          #> cat   13.02696 13.05754  valence_df <- tibble::as_tibble(emb, rownames = \"token\") valence_df |> sim_matrix(dim_1:dim_25, tidy_output = TRUE) #> # A tibble: 3 × 3 #>   doc_id_1 doc_id_2 cosine    #>      <int>    <int> <dist>    #> 1        1        2 0.8680218 #> 2        1        3 0.7297673 #> 3        2        3 0.7455769"},{"path":"https://rimonim.github.io/embedplyr/reference/sim_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Similarity and Distance Metrics — dot_prod","title":"Similarity and Distance Metrics — dot_prod","text":"Metrics measuring relationships vector embeddings.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/sim_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Similarity and Distance Metrics — dot_prod","text":"","code":"dot_prod(x, y)  cos_sim(x, y)  euc_dist(x, y)  minkowski_dist(x, y, p = 1)  anchored_sim(x, pos, neg)"},{"path":"https://rimonim.github.io/embedplyr/reference/sim_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Similarity and Distance Metrics — dot_prod","text":"x numeric vector y numeric vector length x p p-norm used compute Minkowski distance pos, neg pair numeric vectors length x; positive negative ends anchored vector","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/sim_metrics.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Similarity and Distance Metrics — dot_prod","text":"dot_prod gives dot product. cos_sim gives cosine similarity (.e. dot product two normalized vectors). euc_dist gives Euclidean distance. anchored_sim gives position x spectrum two anchor points, vectors aligned pos given score 1 aligned neg given score 0. anchored vectors, see Data Science Psychology: Natural Language, Chapter 20. Note , given set values x, anchored_sim(x, pos, neg) perfectly correlated dot_prod(x, pos - neg).","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/sim_metrics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Similarity and Distance Metrics — dot_prod","text":"","code":"vec1 <- c(1, 5, 2) vec2 <- c(4, 2, 2) vec3 <- c(1, -2, -13)  dot_prod(vec1, vec2) #> [1] 18 cos_sim(vec1, vec2) #> [1] 0.6708204 euc_dist(vec1, vec2) #> [1] 4.242641 anchored_sim(vec1, vec2, vec3) #> [1] 1.012"},{"path":"https://rimonim.github.io/embedplyr/reference/sim_metrics_mat_vec.html","id":null,"dir":"Reference","previous_headings":"","what":"Similarity and Distance Between A Matrix and a Vector — dot_prod_mat_vec","title":"Similarity and Distance Between A Matrix and a Vector — dot_prod_mat_vec","text":"functions equivalent calling vector similarity metrics row matrix, use matrix operations therefore much faster.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/sim_metrics_mat_vec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Similarity and Distance Between A Matrix and a Vector — dot_prod_mat_vec","text":"","code":"dot_prod_mat_vec(x, y)  cos_sim_mat_vec(x, y)  cos_sim_squished_mat_vec(x, y)  euc_dist_mat_vec(x, y)  minkowski_dist_mat_vec(x, y, p = 1)  anchored_sim_mat_vec(x, pos, neg)"},{"path":"https://rimonim.github.io/embedplyr/reference/sim_metrics_mat_vec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Similarity and Distance Between A Matrix and a Vector — dot_prod_mat_vec","text":"x numeric matrix embeddings object y numeric vector length ncol(x) p p-norm used compute Minkowski distance","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/sim_metrics_mat_vec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Similarity and Distance Between A Matrix and a Vector — dot_prod_mat_vec","text":"named numeric vector length nrow(x)","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/sim_metrics_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Similarity and Distance Matrices — dot_prod_matrix","title":"Similarity and Distance Matrices — dot_prod_matrix","text":"functions compute pairwise similarity metrics row matrix.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/sim_metrics_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Similarity and Distance Matrices — dot_prod_matrix","text":"","code":"dot_prod_matrix(x, tidy_output = FALSE)  cos_sim_matrix(x, tidy_output = FALSE)  cos_sim_squished_matrix(x, tidy_output = FALSE)  euc_dist_matrix(x, tidy_output = FALSE)  minkowski_dist_matrix(x, p = 1, tidy_output = FALSE)"},{"path":"https://rimonim.github.io/embedplyr/reference/sim_metrics_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Similarity and Distance Matrices — dot_prod_matrix","text":"x numeric matrix embeddings object tidy_output logical. FALSE (default), output stats::dist object. TRUE, output tibble columns doc_id_1, doc_id_2, similarity distance metric. p p-norm used compute Minkowski distance","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/sim_metrics_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Similarity and Distance Matrices — dot_prod_matrix","text":"named numeric vector length nrow(x)","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/textstat_embedding.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Text Embeddings by Averaging Word Embeddings — textstat_embedding","title":"Get Text Embeddings by Averaging Word Embeddings — textstat_embedding","text":"textstat_embedding() takes 'quanteda' dfm. embed_docs() versatile function acts directly either character vector column texts dataframe.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/textstat_embedding.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Text Embeddings by Averaging Word Embeddings — textstat_embedding","text":"","code":"textstat_embedding(   dfm,   model,   w = NULL,   method = \"mean\",   output_embeddings = FALSE )  embed_docs(x, ...)  # Default S3 method embed_docs(   x,   model,   w = NULL,   method = \"mean\",   ...,   tolower = TRUE,   output_embeddings = FALSE )  # S3 method for class 'data.frame' embed_docs(   x,   text_col,   model,   id_col = NULL,   w = NULL,   method = \"mean\",   ...,   .keep_all = FALSE,   tolower = TRUE,   output_embeddings = FALSE )"},{"path":"https://rimonim.github.io/embedplyr/reference/textstat_embedding.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Text Embeddings by Averaging Word Embeddings — textstat_embedding","text":"dfm quanteda dfm model embeddings object. embed_docs(), model can alternatively function takes character vector outputs dataframe row element input. w optional weighting embeddings model model embeddings object. See average_embedding(). method method use averaging. See average_embedding(). Note method = \"median\" use matrix operations may therefore slow datasets many documents. output_embeddings FALSE (default) returns tibble. TRUE returns embeddings object. See 'Value' details. x character vector, data frame, data frame extension (e.g. tibble) ... additional parameters pass quanteda::tokens() user-specified modeling function tolower logical. Convert text lowercase? model embeddings object, value passed quanteda::dfm(). text_col string. column texts compute embeddings id_col optional string. column unique document ids .keep_all logical. Keep columns input? Ignored output_embeddings = TRUE.","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/textstat_embedding.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Text Embeddings by Averaging Word Embeddings — textstat_embedding","text":"output_embeddings = FALSE, tibble columns doc_id, dim_1, dim_2, etc. similar. .keep_all = TRUE, new columns appear existing ones. output_embeddings = TRUE, embeddings object document ids rownames.","code":""},{"path":[]},{"path":"https://rimonim.github.io/embedplyr/reference/textstat_embedding.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Text Embeddings by Averaging Word Embeddings — textstat_embedding","text":"","code":"texts <- c(\"this says one thing\", \"and this says another\") texts_embeddings <- embed_docs(texts, glove_twitter_25d) texts_embeddings #> # A tibble: 2 × 26 #>   doc_id  dim_1 dim_2  dim_3  dim_4   dim_5  dim_6 dim_7  dim_8   dim_9  dim_10 #>   <chr>   <dbl> <dbl>  <dbl>  <dbl>   <dbl>  <dbl> <dbl>  <dbl>   <dbl>   <dbl> #> 1 text1   0.114 0.167 0.180  -0.144 -0.0492 -0.465  1.77 -0.161 -0.414  -0.0989 #> 2 text2  -0.289 0.297 0.0145 -0.108 -0.248  -0.495  1.58 -0.234 -0.0946 -0.177  #> # ℹ 15 more variables: dim_11 <dbl>, dim_12 <dbl>, dim_13 <dbl>, dim_14 <dbl>, #> #   dim_15 <dbl>, dim_16 <dbl>, dim_17 <dbl>, dim_18 <dbl>, dim_19 <dbl>, #> #   dim_20 <dbl>, dim_21 <dbl>, dim_22 <dbl>, dim_23 <dbl>, dim_24 <dbl>, #> #   dim_25 <dbl>  # quanteda workflow library(quanteda) texts_dfm <- dfm(tokens(texts))  texts_embeddings <- textstat_embedding(texts_dfm, glove_twitter_25d) texts_embeddings #> # A tibble: 2 × 26 #>   doc_id  dim_1 dim_2  dim_3  dim_4   dim_5  dim_6 dim_7  dim_8   dim_9  dim_10 #>   <chr>   <dbl> <dbl>  <dbl>  <dbl>   <dbl>  <dbl> <dbl>  <dbl>   <dbl>   <dbl> #> 1 text1   0.114 0.167 0.180  -0.144 -0.0492 -0.465  1.77 -0.161 -0.414  -0.0989 #> 2 text2  -0.289 0.297 0.0145 -0.108 -0.248  -0.495  1.58 -0.234 -0.0946 -0.177  #> # ℹ 15 more variables: dim_11 <dbl>, dim_12 <dbl>, dim_13 <dbl>, dim_14 <dbl>, #> #   dim_15 <dbl>, dim_16 <dbl>, dim_17 <dbl>, dim_18 <dbl>, dim_19 <dbl>, #> #   dim_20 <dbl>, dim_21 <dbl>, dim_22 <dbl>, dim_23 <dbl>, dim_24 <dbl>, #> #   dim_25 <dbl>  # dplyr workflow texts_df <- data.frame(text = texts) texts_embeddings <- texts_df |> embed_docs(\"text\", glove_twitter_25d) texts_embeddings #> # A tibble: 2 × 26 #>   doc_id  dim_1 dim_2  dim_3  dim_4   dim_5  dim_6 dim_7  dim_8   dim_9  dim_10 #>   <chr>   <dbl> <dbl>  <dbl>  <dbl>   <dbl>  <dbl> <dbl>  <dbl>   <dbl>   <dbl> #> 1 text1   0.114 0.167 0.180  -0.144 -0.0492 -0.465  1.77 -0.161 -0.414  -0.0989 #> 2 text2  -0.289 0.297 0.0145 -0.108 -0.248  -0.495  1.58 -0.234 -0.0946 -0.177  #> # ℹ 15 more variables: dim_11 <dbl>, dim_12 <dbl>, dim_13 <dbl>, dim_14 <dbl>, #> #   dim_15 <dbl>, dim_16 <dbl>, dim_17 <dbl>, dim_18 <dbl>, dim_19 <dbl>, #> #   dim_20 <dbl>, dim_21 <dbl>, dim_22 <dbl>, dim_23 <dbl>, dim_24 <dbl>, #> #   dim_25 <dbl>"},{"path":"https://rimonim.github.io/embedplyr/reference/token_index_add.html","id":null,"dir":"Reference","previous_headings":"","what":"Update hash table after additions — token_index_add","title":"Update hash table after additions — token_index_add","text":"Update hash table additions","code":""},{"path":"https://rimonim.github.io/embedplyr/reference/token_index_add.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update hash table after additions — token_index_add","text":"","code":"token_index_add(embeddings, added_tokens)"},{"path":"https://rimonim.github.io/embedplyr/reference/token_index_add.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update hash table after additions — token_index_add","text":"embeddings embeddings object added_tokens tokens added hash table","code":""}]
